{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMocZv50SG6hH4rNMJHpiNa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f825d4b647e54baf8cc941915977c208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cfa4d13782743699367b5cb85f92719",
              "IPY_MODEL_c2de79c661bf4e4ba96614d573119025",
              "IPY_MODEL_b0f1e9d58165488a942813b3633b1e1b"
            ],
            "layout": "IPY_MODEL_42ae99323ec846df9d7c460122045c0b"
          }
        },
        "5cfa4d13782743699367b5cb85f92719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa091ab2c36459ab6c47eb8269342c4",
            "placeholder": "​",
            "style": "IPY_MODEL_eb695ffc45e141ddba3a64a9d59cf2a7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c2de79c661bf4e4ba96614d573119025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44c4bd5290a46bc9861ab6d225ba42b",
            "max": 181297,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be6fedbee2504f4c82aa037cd8b162a7",
            "value": 181297
          }
        },
        "b0f1e9d58165488a942813b3633b1e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fdb63f390c84567b3d2d32c2195035c",
            "placeholder": "​",
            "style": "IPY_MODEL_5a67f0a69b7746abab29bdd8606bcb52",
            "value": " 181k/181k [00:00&lt;00:00, 2.33MB/s]"
          }
        },
        "42ae99323ec846df9d7c460122045c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fa091ab2c36459ab6c47eb8269342c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb695ffc45e141ddba3a64a9d59cf2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b44c4bd5290a46bc9861ab6d225ba42b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6fedbee2504f4c82aa037cd8b162a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fdb63f390c84567b3d2d32c2195035c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a67f0a69b7746abab29bdd8606bcb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6456f4ecd4464d3fa6d16f0692cb82e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ad062bc372b430c98b67a0c1fe218be",
              "IPY_MODEL_af4094bcae3c42e189b557b892eaa2d3",
              "IPY_MODEL_17d5f586fe7741fa8bfae4e7d33506f4"
            ],
            "layout": "IPY_MODEL_d1356d2945e544b88d40696ffbc19e3e"
          }
        },
        "9ad062bc372b430c98b67a0c1fe218be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_104c61ff60214ef0acc1e2d756ee6741",
            "placeholder": "​",
            "style": "IPY_MODEL_1dc5ef188c594914bfb29a6de98f795e",
            "value": "tokenizer.json: 100%"
          }
        },
        "af4094bcae3c42e189b557b892eaa2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a048f6b28d941798f34a0391a9fee35",
            "max": 9264445,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67395a76a4ea429982b376417029dfc5",
            "value": 9264445
          }
        },
        "17d5f586fe7741fa8bfae4e7d33506f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a80bcce21048cb8e1c30d08627bf61",
            "placeholder": "​",
            "style": "IPY_MODEL_c516403c73a2455fa2f7b7ac20741a68",
            "value": " 9.26M/9.26M [00:00&lt;00:00, 22.3MB/s]"
          }
        },
        "d1356d2945e544b88d40696ffbc19e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104c61ff60214ef0acc1e2d756ee6741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dc5ef188c594914bfb29a6de98f795e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a048f6b28d941798f34a0391a9fee35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67395a76a4ea429982b376417029dfc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50a80bcce21048cb8e1c30d08627bf61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c516403c73a2455fa2f7b7ac20741a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5539abc9d1df4042a7e6376aae0921e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27c21fe88f03445cb61fea1ce4236f34",
              "IPY_MODEL_3fabcae387fe4dd8a09b0578f1216e66",
              "IPY_MODEL_bdbc1d5f1b9849c085f0481186143e1a"
            ],
            "layout": "IPY_MODEL_7b1a9379c3934807bef41559424b65fc"
          }
        },
        "27c21fe88f03445cb61fea1ce4236f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d1d067648b460fbeff269b44afd243",
            "placeholder": "​",
            "style": "IPY_MODEL_bb0aedd53a5c479daf0ee3cba5e92965",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3fabcae387fe4dd8a09b0578f1216e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1676e313e03c44d38cf9ad03df66d401",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bf76da9a2864cc4a0a8cf90cc1731dd",
            "value": 414
          }
        },
        "bdbc1d5f1b9849c085f0481186143e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b9f784f63d4c349046e813dc338674",
            "placeholder": "​",
            "style": "IPY_MODEL_331b13ca72784713bca655f73e00804a",
            "value": " 414/414 [00:00&lt;00:00, 34.3kB/s]"
          }
        },
        "7b1a9379c3934807bef41559424b65fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d1d067648b460fbeff269b44afd243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb0aedd53a5c479daf0ee3cba5e92965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1676e313e03c44d38cf9ad03df66d401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf76da9a2864cc4a0a8cf90cc1731dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82b9f784f63d4c349046e813dc338674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331b13ca72784713bca655f73e00804a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfa7eae7e8c949d8b34519b8c42ff436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1a820ce638143a7a3880a32ed299a32",
              "IPY_MODEL_eff5891f34224f51a24a0d860964a9b0",
              "IPY_MODEL_b0cecf0191764ff29671cdaa92b587ce"
            ],
            "layout": "IPY_MODEL_905cdc8745a64927a8bf1854fc20aa4b"
          }
        },
        "d1a820ce638143a7a3880a32ed299a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f1a40bd62c74097a1fd71d991e6f826",
            "placeholder": "​",
            "style": "IPY_MODEL_6296070c73024432a601d09995c6d0dc",
            "value": "config.json: 100%"
          }
        },
        "eff5891f34224f51a24a0d860964a9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de03259ecf254daebae5b60c188acff7",
            "max": 1163,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcb2d405c53542ba9fbf14f41b14f163",
            "value": 1163
          }
        },
        "b0cecf0191764ff29671cdaa92b587ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43ea9c9c056e4eb09d35e43909275aea",
            "placeholder": "​",
            "style": "IPY_MODEL_65e9cdbb78f04968ab7faeaa736fa373",
            "value": " 1.16k/1.16k [00:00&lt;00:00, 108kB/s]"
          }
        },
        "905cdc8745a64927a8bf1854fc20aa4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1a40bd62c74097a1fd71d991e6f826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6296070c73024432a601d09995c6d0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de03259ecf254daebae5b60c188acff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb2d405c53542ba9fbf14f41b14f163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43ea9c9c056e4eb09d35e43909275aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e9cdbb78f04968ab7faeaa736fa373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5db1db0e85145d5aabd66d30ab1152f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63f7cb32892844eaa732a331bc872e0a",
              "IPY_MODEL_5aa879bb90d74fc191549bc602b6a506",
              "IPY_MODEL_0931ef9366b64208af98263be3e61614"
            ],
            "layout": "IPY_MODEL_133f3b741f9e491f8ba7a0f3aa6a5a75"
          }
        },
        "63f7cb32892844eaa732a331bc872e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14dae34c876e472d9f009956c8e054f6",
            "placeholder": "​",
            "style": "IPY_MODEL_f1424427bb514a599ccee6c38e98beb0",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "5aa879bb90d74fc191549bc602b6a506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4130b8d4414427bd0c0a506468cda6",
            "max": 111243,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a1a1e85dd6946269a97013b81a3a31c",
            "value": 111243
          }
        },
        "0931ef9366b64208af98263be3e61614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b51768f0fe4e7087d0014045601fc3",
            "placeholder": "​",
            "style": "IPY_MODEL_16a08462a353482c808bb596367ca2d0",
            "value": " 111k/111k [00:00&lt;00:00, 8.52MB/s]"
          }
        },
        "133f3b741f9e491f8ba7a0f3aa6a5a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14dae34c876e472d9f009956c8e054f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1424427bb514a599ccee6c38e98beb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea4130b8d4414427bd0c0a506468cda6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a1a1e85dd6946269a97013b81a3a31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66b51768f0fe4e7087d0014045601fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a08462a353482c808bb596367ca2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ba38fc2fe7b4c6990808f5e587dd8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c2514a89d39414f8fc6ae60a960d63f",
              "IPY_MODEL_5d79008cac23434bb7e6eaac60080790",
              "IPY_MODEL_7b5f947b3f084d16b49d36e3aac859c4"
            ],
            "layout": "IPY_MODEL_94110fd58e9040d9ad8848e3b04957b7"
          }
        },
        "7c2514a89d39414f8fc6ae60a960d63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01202b48d5fd4437b7eb4ad33ed70850",
            "placeholder": "​",
            "style": "IPY_MODEL_609014a40c47406e9aae25f85cf77827",
            "value": "Downloading shards: 100%"
          }
        },
        "5d79008cac23434bb7e6eaac60080790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf640736d8094b1cae434a65e12869ce",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7bc5538ff624311ae1f21cc5833c455",
            "value": 2
          }
        },
        "7b5f947b3f084d16b49d36e3aac859c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8836f6d7434691905cd593f1ba5436",
            "placeholder": "​",
            "style": "IPY_MODEL_be58d3b23f6d4ce6b28283299dbc7f2e",
            "value": " 2/2 [03:49&lt;00:00, 111.09s/it]"
          }
        },
        "94110fd58e9040d9ad8848e3b04957b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01202b48d5fd4437b7eb4ad33ed70850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "609014a40c47406e9aae25f85cf77827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf640736d8094b1cae434a65e12869ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7bc5538ff624311ae1f21cc5833c455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8836f6d7434691905cd593f1ba5436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be58d3b23f6d4ce6b28283299dbc7f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01c984c60fbb4cd3955221dc472281e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce7a7421c4dd4487a994e863f7b6a7a0",
              "IPY_MODEL_8114acee07c841bbb0b4f1589d088ea1",
              "IPY_MODEL_96e9f5cbd20040768621c3eee864337a"
            ],
            "layout": "IPY_MODEL_cd4e280721e848029d012897d59e8df9"
          }
        },
        "ce7a7421c4dd4487a994e863f7b6a7a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8563182e4d447a3adc8c04c102ccd7d",
            "placeholder": "​",
            "style": "IPY_MODEL_8cf252cd2b364c35bf6dff2edf271b6f",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "8114acee07c841bbb0b4f1589d088ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_789cde0c43384b7bb137f45396fb6e0e",
            "max": 4981972934,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8834acf3899442f1a491719c7dcd8f3f",
            "value": 4981972934
          }
        },
        "96e9f5cbd20040768621c3eee864337a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dd4d0a5d45a48f7a4c3704eb2a594c4",
            "placeholder": "​",
            "style": "IPY_MODEL_fe66a088e1924b2e85269c7b8cedc415",
            "value": " 4.98G/4.98G [02:14&lt;00:00, 42.4MB/s]"
          }
        },
        "cd4e280721e848029d012897d59e8df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8563182e4d447a3adc8c04c102ccd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf252cd2b364c35bf6dff2edf271b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "789cde0c43384b7bb137f45396fb6e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8834acf3899442f1a491719c7dcd8f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dd4d0a5d45a48f7a4c3704eb2a594c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe66a088e1924b2e85269c7b8cedc415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ba24e0cc524b6fbf445dfb59465162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bebfba2393c24bbc9da6b8998f96b29b",
              "IPY_MODEL_75e2d67ec9204d438fe85c29c3ece3af",
              "IPY_MODEL_dcbd36e1bb054c379fbee3ba7a51064c"
            ],
            "layout": "IPY_MODEL_02e00a11d1204bfd92f3b820a0c746e8"
          }
        },
        "bebfba2393c24bbc9da6b8998f96b29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a31fd1d31524ca88e523faba1e8535f",
            "placeholder": "​",
            "style": "IPY_MODEL_70ddbc247234465f99564714d13ac9ae",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "75e2d67ec9204d438fe85c29c3ece3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3bef29980945b6a1e9b4482b45d0a8",
            "max": 3837566594,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07634d29e8914db98f531caea74f61f5",
            "value": 3837566594
          }
        },
        "dcbd36e1bb054c379fbee3ba7a51064c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a61525e5634d449e67101bf73207c3",
            "placeholder": "​",
            "style": "IPY_MODEL_6781fb91808f46318283a9b72537a78f",
            "value": " 3.84G/3.84G [01:33&lt;00:00, 33.2MB/s]"
          }
        },
        "02e00a11d1204bfd92f3b820a0c746e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a31fd1d31524ca88e523faba1e8535f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70ddbc247234465f99564714d13ac9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a3bef29980945b6a1e9b4482b45d0a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07634d29e8914db98f531caea74f61f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00a61525e5634d449e67101bf73207c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6781fb91808f46318283a9b72537a78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d96b00ac72841f594def3eac6372d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6056d7dd959e4605ac396ef45841cae8",
              "IPY_MODEL_c804bb443961499d9ff9fd1840134904",
              "IPY_MODEL_76de4172fd304d6fabe728e82639dc73"
            ],
            "layout": "IPY_MODEL_3ff374f6d53c489697bde39581d48c27"
          }
        },
        "6056d7dd959e4605ac396ef45841cae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b289b40b5da49d88b6b237f27dc9e49",
            "placeholder": "​",
            "style": "IPY_MODEL_a0a57a5625f04080b640f6e70adab9b2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c804bb443961499d9ff9fd1840134904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c5aba850d694a08af45ee00387e8baa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fca98db2e294448a19d776449d7bbf1",
            "value": 2
          }
        },
        "76de4172fd304d6fabe728e82639dc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d218815b95a45ae8b706444e4e42e65",
            "placeholder": "​",
            "style": "IPY_MODEL_385972638aac4147a122266b0ea93104",
            "value": " 2/2 [00:03&lt;00:00,  1.75s/it]"
          }
        },
        "3ff374f6d53c489697bde39581d48c27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b289b40b5da49d88b6b237f27dc9e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a57a5625f04080b640f6e70adab9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c5aba850d694a08af45ee00387e8baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fca98db2e294448a19d776449d7bbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d218815b95a45ae8b706444e4e42e65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385972638aac4147a122266b0ea93104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cddd73b3f4f54a3cac61b652ecbfc971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bec88fe0b104c71b8df258c0e54641a",
              "IPY_MODEL_8540888f5c764e10be42b40323826fbd",
              "IPY_MODEL_590bae9821c546429d4f5420ab5b4f5e"
            ],
            "layout": "IPY_MODEL_465d324716d54bdc92fc045e29970a8a"
          }
        },
        "9bec88fe0b104c71b8df258c0e54641a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47de4d9176e94fe2acf87110f6d08158",
            "placeholder": "​",
            "style": "IPY_MODEL_b7a0486e92a54cabb004d373125f9cec",
            "value": "generation_config.json: 100%"
          }
        },
        "8540888f5c764e10be42b40323826fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1b14f29795844d1ba4fd17898469104",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_501d0caf642349eb9adb209a613ba1ab",
            "value": 116
          }
        },
        "590bae9821c546429d4f5420ab5b4f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ec5a04d05314329aba75ff6a4a957a2",
            "placeholder": "​",
            "style": "IPY_MODEL_796d3ae309534d0690de3bb6030ecdcf",
            "value": " 116/116 [00:00&lt;00:00, 8.92kB/s]"
          }
        },
        "465d324716d54bdc92fc045e29970a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47de4d9176e94fe2acf87110f6d08158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7a0486e92a54cabb004d373125f9cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1b14f29795844d1ba4fd17898469104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501d0caf642349eb9adb209a613ba1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ec5a04d05314329aba75ff6a4a957a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796d3ae309534d0690de3bb6030ecdcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68358064dace4c55819db0921ba4d9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30fcecb9123c41b09e1e8897776d1a74",
              "IPY_MODEL_b6ea5717c1c74da4a7f3fc456faf7b43",
              "IPY_MODEL_46db7854b4fb4953b80f9c30f275ae3d"
            ],
            "layout": "IPY_MODEL_86c9a32dcde74aefa5456ca792db0d4c"
          }
        },
        "30fcecb9123c41b09e1e8897776d1a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67067f26dd9c4962ab37e2d957a22796",
            "placeholder": "​",
            "style": "IPY_MODEL_4a006c2529df4b07be8b9dd26d544223",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b6ea5717c1c74da4a7f3fc456faf7b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9d38fe4e354042ae984fc52d76fbf0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9407fa28625f4cab8ffbd375bda9ee19",
            "value": 2
          }
        },
        "46db7854b4fb4953b80f9c30f275ae3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5175b519445c47678b8ada5792e9f215",
            "placeholder": "​",
            "style": "IPY_MODEL_67c2aeb440604b488601b2c28cde4952",
            "value": " 2/2 [00:04&lt;00:00,  1.99s/it]"
          }
        },
        "86c9a32dcde74aefa5456ca792db0d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67067f26dd9c4962ab37e2d957a22796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a006c2529df4b07be8b9dd26d544223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef9d38fe4e354042ae984fc52d76fbf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9407fa28625f4cab8ffbd375bda9ee19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5175b519445c47678b8ada5792e9f215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c2aeb440604b488601b2c28cde4952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjleece/rag-experimentation-framework/blob/main/RAG_Experimentation_Framework_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you use this code, please cite:\n",
        "\n",
        "{\n",
        "  title = {RAG Experimentation Framework},\n",
        "\n",
        "  author = {Bill Leece},\n",
        "\n",
        "  year = {2024}\n",
        "}"
      ],
      "metadata": {
        "id": "wZ0kV_UtQn5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "_lHNBLR-92Zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers --quiet\n",
        "#!pip install -U optimum --quiet\n",
        "!pip install -U accelerate  --quiet\n",
        "!pip install -U bitsandbytes  --quiet\n",
        "!pip install -U torch --quiet\n",
        "!pip install -U sentencepiece --quiet\n",
        "!pip install -U llama-index --quiet\n",
        "!pip install -U llama-index-llms-mistralai --quiet\n",
        "!pip install -U llama-index-embeddings-mistralai --quiet\n",
        "!pip install -U llama-index-llms-langchain --quiet\n",
        "!pip install -U langchain --quiet\n",
        "!pip install -U langchain-community --quiet\n",
        "!pip install -U langchain_huggingface --quiet\n",
        "!pip install -U faiss-gpu --quiet"
      ],
      "metadata": {
        "id": "4g_Vs7wgZW-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b04998-e649-4c54-fc8b-69d7d5ceaba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.0/189.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.6/254.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import faiss\n",
        "import transformers\n",
        "import torch\n",
        "import gc\n",
        "from google.colab import drive, userdata\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from llama_index.llms.mistralai import MistralAI\n",
        "from llama_index.embeddings.mistralai import MistralAIEmbedding\n",
        "from llama_index.core import SimpleDirectoryReader, Settings\n",
        "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
        "import time\n",
        "from typing import List, Dict, Tuple\n",
        "from contextlib import contextmanager"
      ],
      "metadata": {
        "id": "Ao7eaSfq-TKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "os.environ[\"MISTRAL_API_KEY\"] = userdata.get('MISTRAL_API_KEY')"
      ],
      "metadata": {
        "id": "YvGHY024-OXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #Use GPUs for quantization!"
      ],
      "metadata": {
        "id": "mxAHV7T_-Xlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DZ1UHTPSPXqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfUKkdCs-wQJ",
        "outputId": "247a5989-7007-4e6e-f06f-0faf29b913b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 13 16:23:27 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   38C    P8              12W /  72W |      4MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experiment Configurations"
      ],
      "metadata": {
        "id": "jkqEV8M_HUKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup configurations\n",
        "MODEL_CONFIGS = {\n",
        "    \"models\": [\n",
        "    #    {\n",
        "    #        \"name\": \"open-mixtral-8x7b\",\n",
        "    #        \"type\": \"mistral_api\",\n",
        "    #        \"tokenizer\": None,  # Not needed for API models\n",
        "    #    },\n",
        "         {\n",
        "            \"name\": \"open-mistral-nemo\",\n",
        "            \"type\": \"mistral_api\",\n",
        "            \"tokenizer\": None,  # Not needed for API models\n",
        "         },\n",
        "        {\n",
        "            \"name\": \"ministral-8b-latest\",\n",
        "            \"type\": \"mistral_api\",\n",
        "            \"tokenizer\": None,  # Not needed for API models\n",
        "        },\n",
        "   #   {\n",
        "   #         \"name\": \"wjleece/quantized-mistral-7b\",\n",
        "   #         \"type\": \"huggingface_quantized\",\n",
        "   #         \"tokenizer\": \"mistralai/Mixtral-8x7B-v0.1\",  # The same tokenizer that works on the base model will work on the quantized model - there is no 'quantized tokenizer'\n",
        "   #          \"quantization_config\": {                    #Quantization config left here as a reference, but not used in the code (as we're using an already quantized model from HuggingFace)\n",
        "   #             \"load_in_4bit\": True,\n",
        "   #             \"bnb_4bit_compute_dtype\": \"float16\",\n",
        "   #             \"bnb_4bit_quant_type\": \"nf4\",\n",
        "   #             \"bnb_4bit_use_double_quant\": False\n",
        "   #         }\n",
        "   #     },\n",
        "      {\n",
        "              \"name\": \"wjleece/quantized-mistral-nemo-12b\",\n",
        "              \"type\": \"huggingface_quantized\",\n",
        "              \"tokenizer\": \"mistralai/Mistral-Nemo-Instruct-2407\",  # The same tokenizer that works on the base model will work on the quantized model - there is no 'quantized tokenizer'\n",
        "              \"quantization_config\": {                    #Quantization config left here as a reference, but not used in the code (as we're using an already quantized model from HuggingFace)\n",
        "                  \"load_in_4bit\": True,\n",
        "                  \"bnb_4bit_compute_dtype\": \"float16\",\n",
        "                  \"bnb_4bit_quant_type\": \"nf4\",\n",
        "                  \"bnb_4bit_use_double_quant\": False\n",
        "             }\n",
        "          },\n",
        "     #  {\n",
        "     #         \"name\": \"wjleece/quantized-mistral-8b\",\n",
        "     #         \"type\": \"huggingface_quantized\",\n",
        "     #         \"tokenizer\": \"mistralai/Ministral-8B-Instruct-2410\",  # The same tokenizer that works on the base model will work on the quantized model - there is no 'quantized tokenizer'\n",
        "     #         \"quantization_config\": {                    #Quantization config left here as a reference, but not used in the code (as we're using an already quantized model from HuggingFace)\n",
        "     #             \"load_in_4bit\": True,\n",
        "     #             \"bnb_4bit_compute_dtype\": \"float16\",\n",
        "     #             \"bnb_4bit_quant_type\": \"nf4\",\n",
        "     #             \"bnb_4bit_use_double_quant\": False\n",
        "     #         }\n",
        "     #     }\n",
        "       ],\n",
        "    #RAG semantic chunking thresholds (higher thresholds --> fewer RAG chunks created)\n",
        "    \"thresholds\": [85, 95] #RAG semantic chunking thresholds (higher thresholds --> fewer RAG chunks created)\n",
        "}\n",
        "\"\"\n",
        "QUESTION_CONFIGS = {\n",
        "    \"questions\": [\n",
        "        \"What were cloud revenues in Q2 2024?\",\n",
        "        \"What were the main drivers of revenue growth in Q2?\",\n",
        "        \"How much did YouTube ad revenues grow in Q2 in APAC?\",\n",
        "        \"Can you summarize recent key antitrust matters?\",\n",
        "        \"What were YouTube ad revenues in Q2?\"\n",
        "    ] #These quetsions should relate to the RAG document --> these are your 'business use cases'\n",
        "}\n",
        "\n",
        "FILE_CONFIGS = {\n",
        "    \"save_directory\": '/content/drive/My Drive/AI/Model_Analysis'\n",
        "}"
      ],
      "metadata": {
        "id": "YDjgk_JhHWkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load RAG Document"
      ],
      "metadata": {
        "id": "e_wxgOGc95sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "documents = SimpleDirectoryReader(input_files=[\"/content/drive/My Drive/AI/Datasets/Google-10-q/goog-10-q-q2-2024.pdf\"]).load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS4Lemk09v9Y",
        "outputId": "3d1cc5be-e495-4edc-c5ac-766e1d7d7a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG PIPELINE Class"
      ],
      "metadata": {
        "id": "MgLxma5M-bZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGPipeline:\n",
        "    def __init__(self):\n",
        "        self.chunk_cache = {}\n",
        "        self.embedding_cache = {}\n",
        "        self.embedding_model = None\n",
        "\n",
        "    def initialize_embedding_model(self):\n",
        "        \"\"\"Initialize the embedding model if not already initialized\"\"\"\n",
        "        if self.embedding_model is None:\n",
        "            mistral_api_key = userdata.get('MISTRAL_API_KEY')\n",
        "            self.embedding_model = MistralAIEmbedding(\n",
        "                model_name=\"mistral-embed\",\n",
        "                api_key=mistral_api_key\n",
        "            )\n",
        "        return self.embedding_model\n",
        "\n",
        "    def create_semantic_chunks(self, documents: List, threshold: int) -> Dict:\n",
        "        \"\"\"Create or retrieve semantic chunks with memory optimization\"\"\"\n",
        "        if self.embedding_model is None:\n",
        "            self.initialize_embedding_model()\n",
        "\n",
        "        if threshold not in self.chunk_cache:\n",
        "            print(f\"Creating new semantic chunks for threshold {threshold}\")\n",
        "\n",
        "            # Clear other thresholds from cache if memory pressure is high\n",
        "            if len(self.chunk_cache) > 2:  # Keep only 2 thresholds in memory\n",
        "                oldest_threshold = min(self.chunk_cache.keys())\n",
        "                if oldest_threshold != threshold:\n",
        "                    del self.chunk_cache[oldest_threshold]\n",
        "                    if oldest_threshold in self.embedding_cache:\n",
        "                        del self.embedding_cache[oldest_threshold]\n",
        "                    gc.collect()\n",
        "\n",
        "            splitter = SemanticSplitterNodeParser(\n",
        "                buffer_size=1,\n",
        "                breakpoint_percentile_threshold=threshold,\n",
        "                embed_model=self.embedding_model\n",
        "            )\n",
        "\n",
        "            nodes = splitter.get_nodes_from_documents(documents)\n",
        "            texts = [node.text for node in nodes]\n",
        "\n",
        "            self.chunk_cache[threshold] = {\n",
        "                'texts': texts\n",
        "            }\n",
        "\n",
        "        return self.chunk_cache[threshold]\n",
        "\n",
        "    def run_cosine_search(self, query: str, threshold: int, k=5) -> List[Dict]:\n",
        "        \"\"\"Run cosine similarity search with memory optimization\"\"\"\n",
        "        if self.embedding_model is None:\n",
        "            self.initialize_embedding_model()\n",
        "\n",
        "        if threshold not in self.embedding_cache:\n",
        "            texts = self.chunk_cache[threshold]['texts']\n",
        "\n",
        "            # Generate embeddings in batches to reduce memory usage\n",
        "            batch_size = 32\n",
        "            embeddings = []\n",
        "\n",
        "            for i in range(0, len(texts), batch_size):\n",
        "                batch_texts = texts[i:i + batch_size]\n",
        "                batch_embeddings = [self.embedding_model.get_text_embedding(text)\n",
        "                                  for text in batch_texts]\n",
        "                embeddings.extend(batch_embeddings)\n",
        "\n",
        "                # Optional: Clear some memory after each batch\n",
        "                if i % (batch_size * 4) == 0:\n",
        "                    gc.collect()\n",
        "\n",
        "            embeddings_array = np.array(embeddings).astype('float32')\n",
        "            normalized_embeddings = embeddings_array / np.linalg.norm(embeddings_array, axis=1)[:, np.newaxis]\n",
        "\n",
        "            dimension = embeddings_array.shape[1]\n",
        "            cosine_index = faiss.IndexFlatIP(dimension)\n",
        "            cosine_index.add(normalized_embeddings)\n",
        "\n",
        "            self.embedding_cache[threshold] = {\n",
        "                'embeddings': embeddings_array,\n",
        "                'cosine_index': cosine_index\n",
        "            }\n",
        "\n",
        "        # Perform search\n",
        "        query_vector = self.embedding_model.get_text_embedding(query)\n",
        "        query_vector = np.array([query_vector]).astype('float32')\n",
        "        query_normalized = query_vector / np.linalg.norm(query_vector)\n",
        "\n",
        "        distances, indices = self.embedding_cache[threshold]['cosine_index'].search(\n",
        "            query_normalized.reshape(1, -1).astype('float32'), k\n",
        "        )\n",
        "\n",
        "        return [\n",
        "            {\n",
        "                'text': self.chunk_cache[threshold]['texts'][idx],\n",
        "                'distance': float(score)\n",
        "            }\n",
        "            for score, idx in zip(distances[0], indices[0])\n",
        "        ]\n",
        "\n",
        "    def generate_response(self, query: str, context_rag: list, model: Dict) -> dict:\n",
        "        \"\"\"Generate response using provided context\"\"\"\n",
        "        try:\n",
        "            context_texts = [doc['text'] for doc in context_rag]\n",
        "            if not context_texts:\n",
        "                return {\"response_text\": \"No relevant context found.\", \"sources\": []}\n",
        "\n",
        "            context = \"\\n\\n\".join(context_texts)\n",
        "\n",
        "            prompt = PromptTemplate(template=\"\"\"\n",
        "            Instructions:\n",
        "\n",
        "            You are a helpful assistant who answers questions from context that has been provided to you.\n",
        "            Given the context information, provide a direct and concise answer to the question: {query}\n",
        "\n",
        "            Focus only on information present in the context. If you don't know the answer, say \"I don't know.\"\n",
        "            You must format your response as a JSON string object, starting with the word \"LLM_Response:\"\n",
        "\n",
        "            Your answer to {query} will be a JSON string object that starts with \"LLM_Response:\" as shown below:\n",
        "\n",
        "            LLM_Response:\n",
        "            {{\n",
        "                \"response_text\": \"Your detailed answer here\",\n",
        "                \"sources\": [\n",
        "                    \"Copy and paste here the exact text segments from the context that you used to generate your answer. Include all relevant segments, verbatim.\"\n",
        "                ]\n",
        "            }}\n",
        "\n",
        "            Important: In your response, the \"sources\" field must contain the exact text passages from the provided context that you used to formulate your answer. Copy these passages word-for-word.\n",
        "\n",
        "            Do not include a hypothetical example in your answer, only include your final answer after \"LLM_Response:\"\n",
        "\n",
        "            The context information that you will use for your answer is below:\n",
        "\n",
        "            ---------------\n",
        "            {context}\n",
        "            ---------------\n",
        "            \"\"\")\n",
        "\n",
        "            formatted_prompt = prompt.format(\n",
        "                context=context,\n",
        "                query=query\n",
        "            )\n",
        "\n",
        "            model_type = model['type']\n",
        "            llm = model['llm']\n",
        "\n",
        "            if model_type == 'mistral_api':\n",
        "                response = llm.complete(formatted_prompt)\n",
        "                response_text = response.text\n",
        "            else:  # huggingface_quantized\n",
        "                response = llm(formatted_prompt)\n",
        "                response_text = response[0].split(\"LLM_Response:\")[-1].strip() if isinstance(response, list) else response.split(\"LLM_Response:\")[-1].strip()\n",
        "\n",
        "            # Try to parse as JSON\n",
        "            try:\n",
        "                if '{' in response_text and '}' in response_text:\n",
        "                    json_str = response_text[response_text.find('{'):response_text.rfind('}')+1]\n",
        "                    parsed_response = json.loads(json_str)\n",
        "                    return {\n",
        "                        \"response_text\": parsed_response.get(\"response_text\", response_text),\n",
        "                        \"sources\": parsed_response.get(\"sources\", [])\n",
        "                    }\n",
        "                else:\n",
        "                    return {\n",
        "                        \"response_text\": response_text,\n",
        "                        \"sources\": []\n",
        "                    }\n",
        "            except json.JSONDecodeError:\n",
        "                return {\n",
        "                    \"response_text\": response_text,\n",
        "                    \"sources\": []\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response: {str(e)}\")\n",
        "            return {\n",
        "                \"response_text\": f\"Error: {str(e)}\",\n",
        "                \"sources\": []\n",
        "            }\n",
        "\n",
        "# Global RAG pipeline instance\n",
        "_GLOBAL_RAG_PIPELINE = None\n"
      ],
      "metadata": {
        "id": "YY5rnivk-bAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experiment Class"
      ],
      "metadata": {
        "id": "05gTul4pIW6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MemoryOptimizedExperimentConfig:\n",
        "    def __init__(self,\n",
        "                 models: List[Dict],\n",
        "                 thresholds: List[int],\n",
        "                 questions: List[str],\n",
        "                 temperature: float):\n",
        "        self.models = models\n",
        "        self.thresholds = thresholds\n",
        "        self.questions = questions\n",
        "        self.temperature = temperature\n",
        "\n",
        "        # Use global RAG pipeline\n",
        "        global _GLOBAL_RAG_PIPELINE\n",
        "        if _GLOBAL_RAG_PIPELINE is None:\n",
        "            print(\"Initializing global RAG pipeline\")\n",
        "            _GLOBAL_RAG_PIPELINE = RAGPipeline()\n",
        "        else:\n",
        "            print(\"Using existing global RAG pipeline\")\n",
        "        self.rag_pipeline = _GLOBAL_RAG_PIPELINE\n",
        "\n",
        "        self.current_model = None\n",
        "        self.current_model_name = None\n",
        "\n",
        "    @contextmanager\n",
        "    def load_model(self, model_config: Dict):\n",
        "        \"\"\"Context manager for lazy loading and proper cleanup of models\"\"\"\n",
        "        try:\n",
        "            model_name = model_config[\"name\"]\n",
        "            model_type = model_config[\"type\"]\n",
        "\n",
        "            # Clear any existing model\n",
        "            self.cleanup_current_model()\n",
        "\n",
        "            if model_type == \"mistral_api\":\n",
        "                mistral_api_key = userdata.get('MISTRAL_API_KEY')\n",
        "                self.current_model = {\n",
        "                    'llm': MistralAI(\n",
        "                        model=model_name,\n",
        "                        temperature=self.temperature,\n",
        "                        api_key=mistral_api_key\n",
        "                    ),\n",
        "                    'type': 'mistral_api'\n",
        "                }\n",
        "            else:  # huggingface_quantized\n",
        "                print(f\"Loading quantized model: {model_name}\")\n",
        "\n",
        "                # Empty CUDA cache before loading new model\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "                tokenizer = AutoTokenizer.from_pretrained(\n",
        "                    pretrained_model_name_or_path=model_config[\"tokenizer\"],\n",
        "                    trust_remote_code=True,\n",
        "                    use_fast=True,\n",
        "                    padding_side=\"left\"\n",
        "                )\n",
        "\n",
        "                model = AutoModelForCausalLM.from_pretrained(\n",
        "                    pretrained_model_name_or_path=model_name,\n",
        "                    device_map=\"auto\",\n",
        "                    trust_remote_code=True,\n",
        "                    torch_dtype=torch.float16,\n",
        "                    use_cache=True,\n",
        "                    low_cpu_mem_usage=True,\n",
        "                )\n",
        "\n",
        "                pipe = pipeline(\n",
        "                    \"text-generation\",\n",
        "                    model=model,\n",
        "                    tokenizer=tokenizer,\n",
        "                    max_new_tokens=512,\n",
        "                    temperature=self.temperature,\n",
        "                    top_p=0.95,\n",
        "                    top_k=50,\n",
        "                    do_sample=True,\n",
        "                    device_map=\"auto\"\n",
        "                )\n",
        "\n",
        "                self.current_model = {\n",
        "                    'llm': HuggingFacePipeline(pipeline=pipe),\n",
        "                    'type': 'huggingface_quantized',\n",
        "                    'model': model,  # Keep reference for cleanup\n",
        "                    'pipe': pipe     # Keep reference for cleanup\n",
        "                }\n",
        "\n",
        "            self.current_model_name = model_name\n",
        "            yield self.current_model\n",
        "\n",
        "        finally:\n",
        "            # Cleanup will happen in cleanup_current_model()\n",
        "            pass\n",
        "\n",
        "    def cleanup_current_model(self):\n",
        "        \"\"\"Clean up the current model and free memory\"\"\"\n",
        "        if self.current_model is not None:\n",
        "            if self.current_model['type'] == 'huggingface_quantized':\n",
        "                # Delete model components explicitly\n",
        "                del self.current_model['llm']\n",
        "                del self.current_model['model']\n",
        "                del self.current_model['pipe']\n",
        "\n",
        "                # Clear CUDA cache\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                # Run garbage collection\n",
        "                gc.collect()\n",
        "\n",
        "            self.current_model = None\n",
        "            self.current_model_name = None\n",
        "\n",
        "    def run_experiment(self):\n",
        "        \"\"\"Run experiments with optimized memory management\"\"\"\n",
        "        results = {\n",
        "            \"metadata\": {\n",
        "                \"timestamp\": time.strftime(\"%Y%m%d-%H%M%S\"),\n",
        "                \"models_tested\": [model[\"name\"] for model in self.models],\n",
        "                \"thresholds_tested\": self.thresholds,\n",
        "                \"temperature\": self.temperature\n",
        "            },\n",
        "            \"results\": []\n",
        "        }\n",
        "\n",
        "        # Process each threshold\n",
        "        for threshold in self.thresholds:\n",
        "            print(f\"\\nProcessing threshold: {threshold}\")\n",
        "            self.rag_pipeline.create_semantic_chunks(documents, threshold)\n",
        "\n",
        "            # Process each model one at a time\n",
        "            for model_config in self.models:\n",
        "                model_name = model_config[\"name\"]\n",
        "                print(f\"\\nTesting model: {model_name}\")\n",
        "\n",
        "                # Use context manager to handle model lifecycle\n",
        "                with self.load_model(model_config) as model:\n",
        "                    # Process all questions for this model and threshold\n",
        "                    for question in self.questions:\n",
        "                        print(f\"Processing question: {question}\")\n",
        "\n",
        "                        context = self.rag_pipeline.run_cosine_search(\n",
        "                            query=question,\n",
        "                            threshold=threshold\n",
        "                        )\n",
        "\n",
        "                        answer = self.rag_pipeline.generate_response(\n",
        "                            query=question,\n",
        "                            context_rag=context,\n",
        "                            model=model\n",
        "                        )\n",
        "\n",
        "                        results[\"results\"].append({\n",
        "                            \"model\": model_name,\n",
        "                            \"threshold\": threshold,\n",
        "                            \"question\": question,\n",
        "                            \"response\": answer\n",
        "                        })\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "tCzG7OE0IiDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluator Class"
      ],
      "metadata": {
        "id": "EpjD-Qz54mfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import tiktoken\n",
        "import textwrap\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "class ExperimentEvaluator:\n",
        "    def __init__(self, api_key: str):\n",
        "        self.client = openai.OpenAI(api_key=api_key)\n",
        "        self.encoder = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "\n",
        "    def _get_baseline_answers(self, questions: List[str], source_doc: str) -> Dict[str, str]:\n",
        "        \"\"\"Get GPT-4o's own answers to the questions as baseline\"\"\"\n",
        "        baseline_prompt = f\"\"\"Source Document:\n",
        "        {source_doc}\n",
        "\n",
        "        Using only the information from the source document above, answer these questions.\n",
        "        Format your response as a valid JSON object with questions as keys and answers as values.\n",
        "        Keep answers concise and factual.\n",
        "\n",
        "        Questions to answer:\n",
        "        {json.dumps(questions, indent=2)}\n",
        "\n",
        "        Response format example:\n",
        "        {{\n",
        "            \"Question 1\": \"Answer 1\",\n",
        "            \"Question 2\": \"Answer 2\"\n",
        "        }}\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"\\n--- Getting Baseline Answers ---\")\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides JSON-formatted answers based on source documents.\"},\n",
        "                    {\"role\": \"user\", \"content\": baseline_prompt}\n",
        "                ],\n",
        "                temperature=0.1\n",
        "            )\n",
        "\n",
        "            content = response.choices[0].message.content\n",
        "            print(\"Baseline response received:\", content[:200] + \"...\")\n",
        "\n",
        "            if '{' in content and '}' in content:\n",
        "                json_str = content[content.find('{'):content.rfind('}')+1]\n",
        "                return json.loads(json_str)\n",
        "            else:\n",
        "                print(\"Warning: No JSON structure found in GPT-4o's baseline response\")\n",
        "                return {\"error\": \"No JSON structure found\", \"questions\": questions}\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Warning: Could not parse GPT-4o's baseline answers as JSON: {str(e)}\")\n",
        "            return {\"error\": \"JSON parsing failed\", \"questions\": questions}\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Error getting baseline answers: {str(e)}\")\n",
        "            return {\"error\": str(e), \"questions\": questions}\n",
        "\n",
        "    def evaluate_experiments(self, experiment_results: Dict, source_doc: str) -> Dict:\n",
        "        \"\"\"Evaluate experiment results using GPT-4o\"\"\"\n",
        "        try:\n",
        "            print(\"\\n=== Starting Evaluation Process ===\")\n",
        "            questions = list(set(result[\"question\"] for result in experiment_results[\"results\"]))\n",
        "            print(f\"Number of unique questions to evaluate: {len(questions)}\")\n",
        "\n",
        "            # Get unique model/threshold combinations\n",
        "            model_threshold_pairs = set((result[\"model\"], result[\"threshold\"])\n",
        "                                     for result in experiment_results[\"results\"])\n",
        "            print(f\"Number of model/threshold combinations: {len(model_threshold_pairs)}\")\n",
        "\n",
        "            # Get baseline answers for comparison\n",
        "            baseline_answers = self._get_baseline_answers(questions, source_doc)\n",
        "            print(\"Baseline answers received\")\n",
        "\n",
        "            # Evaluate each model/threshold/question combination separately\n",
        "            all_evaluations = []\n",
        "\n",
        "            for model, threshold in model_threshold_pairs:\n",
        "                print(f\"\\nEvaluating model: {model}, threshold: {threshold}\")\n",
        "                relevant_results = [r for r in experiment_results[\"results\"]\n",
        "                                  if r[\"model\"] == model and r[\"threshold\"] == threshold]\n",
        "\n",
        "                for result in relevant_results:\n",
        "                    evaluation_prompt = f\"\"\"Evaluate this specific response:\n",
        "\n",
        "                    Question: {result[\"question\"]}\n",
        "                    Baseline Answer: {baseline_answers.get(result[\"question\"], \"No baseline available\")}\n",
        "                    Model: {result[\"model\"]}\n",
        "                    Threshold: {result[\"threshold\"]}\n",
        "                    Response: {json.dumps(result[\"response\"], indent=2)}\n",
        "\n",
        "                    Score the response on these criteria (0-100):\n",
        "                    - Accuracy: How well does it match the baseline/source\n",
        "                    - Conciseness: Clear, direct answer without extra information\n",
        "                    - Source Attribution: Uses relevant source text as evidence\n",
        "                    - Reasonableness: Answer is properly contextualized\n",
        "\n",
        "                    Provide your evaluation in this exact JSON format:\n",
        "                    {{\n",
        "                        \"model\": \"{result[\"model\"]}\",\n",
        "                        \"threshold\": {result[\"threshold\"]},\n",
        "                        \"question\": \"{result[\"question\"]}\",\n",
        "                        \"scores\": {{\n",
        "                            \"accuracy\": <score>,\n",
        "                            \"conciseness\": <score>,\n",
        "                            \"source_attribution\": <score>,\n",
        "                            \"reasonableness\": <score>\n",
        "                        }},\n",
        "                        \"composite_score\": <average of scores>,\n",
        "                        \"explanation\": \"detailed explanation\"\n",
        "                    }}\"\"\"\n",
        "\n",
        "                    try:\n",
        "                        response = self.client.chat.completions.create(\n",
        "                            model=\"gpt-4o\",\n",
        "                            messages=[\n",
        "                                {\"role\": \"system\", \"content\": \"You are an expert at evaluating LLM responses for accuracy and quality.\"},\n",
        "                                {\"role\": \"user\", \"content\": evaluation_prompt}\n",
        "                            ],\n",
        "                            temperature=0.7,\n",
        "                            max_tokens=1000\n",
        "                        )\n",
        "\n",
        "                        content = response.choices[0].message.content\n",
        "                        print(f\"\\nEvaluating {model}/{threshold}/{result['question']}\")\n",
        "                        print(\"Raw response:\", content[:200] + \"...\")\n",
        "\n",
        "                        if '{' in content and '}' in content:\n",
        "                            json_str = content[content.find('{'):content.rfind('}')+1]\n",
        "                            evaluation = json.loads(json_str)\n",
        "                            all_evaluations.append(evaluation)\n",
        "                        else:\n",
        "                            print(f\"No JSON found in response for {model}/{threshold}/{result['question']}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error evaluating {model}/{threshold}/{result['question']}: {str(e)}\")\n",
        "\n",
        "            # Create final evaluation structure\n",
        "            final_evaluation = {\n",
        "                \"metadata\": {\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"model_used\": \"gpt-4o\",\n",
        "                    \"num_permutations_evaluated\": len(experiment_results[\"results\"]),\n",
        "                    \"num_questions_evaluated\": len(questions),\n",
        "                    \"evaluation_status\": \"success\" if all_evaluations else \"failed\"\n",
        "                },\n",
        "                \"evaluations\": all_evaluations,\n",
        "                \"summary\": self._generate_summary(all_evaluations)\n",
        "            }\n",
        "\n",
        "            return final_evaluation\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nCritical error in evaluation process: {str(e)}\")\n",
        "            return self._create_default_evaluation(experiment_results)\n",
        "\n",
        "    def _generate_summary(self, evaluations: List[Dict]) -> Dict:\n",
        "        \"\"\"Generate summary statistics from evaluations\"\"\"\n",
        "        if not evaluations:\n",
        "            return {\n",
        "                \"overall_performance\": \"No evaluations available\",\n",
        "                \"optimal_permutation\": \"Not available\",\n",
        "                \"performance_analysis\": \"Evaluation process failed\"\n",
        "            }\n",
        "\n",
        "        # Calculate average scores by model/threshold\n",
        "        model_scores = {}\n",
        "        for eval in evaluations:\n",
        "            key = (eval[\"model\"], eval[\"threshold\"])\n",
        "            if key not in model_scores:\n",
        "                model_scores[key] = {\n",
        "                    \"count\": 0,\n",
        "                    \"total_accuracy\": 0,\n",
        "                    \"total_conciseness\": 0,\n",
        "                    \"total_source_attribution\": 0,\n",
        "                    \"total_reasonableness\": 0,\n",
        "                    \"total_composite\": 0\n",
        "                }\n",
        "\n",
        "            scores = model_scores[key]\n",
        "            scores[\"count\"] += 1\n",
        "            scores[\"total_accuracy\"] += eval[\"scores\"][\"accuracy\"]\n",
        "            scores[\"total_conciseness\"] += eval[\"scores\"][\"conciseness\"]\n",
        "            scores[\"total_source_attribution\"] += eval[\"scores\"][\"source_attribution\"]\n",
        "            scores[\"total_reasonableness\"] += eval[\"scores\"][\"reasonableness\"]\n",
        "            scores[\"total_composite\"] += eval[\"composite_score\"]\n",
        "\n",
        "        # Find best performing model/threshold\n",
        "        best_score = 0\n",
        "        best_model = None\n",
        "        best_threshold = None\n",
        "\n",
        "        for (model, threshold), scores in model_scores.items():\n",
        "            avg_composite = scores[\"total_composite\"] / scores[\"count\"]\n",
        "            if avg_composite > best_score:\n",
        "                best_score = avg_composite\n",
        "                best_model = model\n",
        "                best_threshold = threshold\n",
        "\n",
        "        return {\n",
        "            \"overall_performance\": f\"Average composite score across all evaluations: {sum(e['composite_score'] for e in evaluations)/len(evaluations):.2f}/100\",\n",
        "            \"optimal_permutation\": f\"Best performance: {best_model} with threshold {best_threshold} (score: {best_score:.2f}/100)\",\n",
        "            \"performance_analysis\": f\"Evaluated {len(evaluations)} responses across {len(model_scores)} model/threshold combinations.\"\n",
        "        }\n",
        "\n",
        "    def _create_default_evaluation(self, experiment_results: Dict) -> Dict:\n",
        "        \"\"\"Create a default evaluation structure when parsing fails\"\"\"\n",
        "        print(\"\\n--- Creating Default Evaluation Due to Failure ---\")\n",
        "        default_eval = {\n",
        "            \"metadata\": {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"model_used\": \"gpt-4o\",\n",
        "                \"num_permutations_evaluated\": len(experiment_results[\"results\"]),\n",
        "                \"num_questions_evaluated\": len(set(r[\"question\"] for r in experiment_results[\"results\"])),\n",
        "                \"evaluation_status\": \"failed\"\n",
        "            },\n",
        "            \"evaluations\": [],\n",
        "            \"summary\": {\n",
        "                \"overall_performance\": \"Evaluation failed - using default structure\",\n",
        "                \"optimal_permutation\": \"Not available\",\n",
        "                \"performance_analysis\": \"Evaluation process encountered errors\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for result in experiment_results[\"results\"]:\n",
        "            default_eval[\"evaluations\"].append({\n",
        "                \"model\": result[\"model\"],\n",
        "                \"threshold\": result[\"threshold\"],\n",
        "                \"question\": result[\"question\"],\n",
        "                \"scores\": {\n",
        "                    \"accuracy\": 0,\n",
        "                    \"conciseness\": 0,\n",
        "                    \"source_attribution\": 0,\n",
        "                    \"reasonableness\": 0\n",
        "                },\n",
        "                \"composite_score\": 0,\n",
        "                \"explanation\": \"Evaluation failed - default scores assigned\"\n",
        "            })\n",
        "\n",
        "        print(\"Created default evaluation with\", len(default_eval[\"evaluations\"]), \"empty evaluations\")\n",
        "        return default_eval\n",
        "\n",
        "    def format_and_save_results(self, experiment_results: Dict, evaluation_results: Dict, save_dir: str):\n",
        "        \"\"\"Format and save both experiment and evaluation results\"\"\"\n",
        "        print(\"\\n=== Starting Results Formatting ===\")\n",
        "        try:\n",
        "            print(\"Input evaluation_results keys:\", list(evaluation_results.keys()))\n",
        "\n",
        "            if not isinstance(evaluation_results, dict):\n",
        "                print(\"Warning: evaluation_results is not a dictionary\")\n",
        "                evaluation_results = self._create_default_evaluation(experiment_results)\n",
        "\n",
        "            if \"metadata\" not in evaluation_results:\n",
        "                print(\"Warning: metadata missing from evaluation_results\")\n",
        "                evaluation_results = self._create_default_evaluation(experiment_results)\n",
        "\n",
        "            # Format experiment results\n",
        "            formatted_experiment = {\n",
        "                \"metadata\": experiment_results.get(\"metadata\", {}),\n",
        "                \"results\": []\n",
        "            }\n",
        "\n",
        "            # Group results by model and threshold\n",
        "            for result in experiment_results[\"results\"]:\n",
        "                formatted_result = {\n",
        "                    \"model\": result[\"model\"],\n",
        "                    \"threshold\": result[\"threshold\"],\n",
        "                    \"question\": result[\"question\"],\n",
        "                    \"response\": {\n",
        "                        \"answer\": result[\"response\"].get(\"response_text\", \"\"),\n",
        "                        \"sources\": result[\"response\"].get(\"sources\", [])\n",
        "                    }\n",
        "                }\n",
        "                formatted_experiment[\"results\"].append(formatted_result)\n",
        "\n",
        "            # Format evaluation results with aggregated scores\n",
        "            formatted_evaluation = {\n",
        "                \"metadata\": evaluation_results[\"metadata\"],\n",
        "                \"model_evaluations\": {},\n",
        "                \"overall_summary\": evaluation_results.get(\"summary\", {})\n",
        "            }\n",
        "\n",
        "            # Process evaluations if they exist\n",
        "            if \"evaluations\" in evaluation_results:\n",
        "                for eval in evaluation_results[\"evaluations\"]:\n",
        "                    model_name = eval[\"model\"]\n",
        "                    threshold = eval[\"threshold\"]\n",
        "\n",
        "                    if model_name not in formatted_evaluation[\"model_evaluations\"]:\n",
        "                        formatted_evaluation[\"model_evaluations\"][model_name] = {\n",
        "                            \"thresholds\": {}\n",
        "                        }\n",
        "\n",
        "                    if threshold not in formatted_evaluation[\"model_evaluations\"][model_name][\"thresholds\"]:\n",
        "                        formatted_evaluation[\"model_evaluations\"][model_name][\"thresholds\"][threshold] = {\n",
        "                            \"questions\": [],\n",
        "                            \"average_scores\": {\n",
        "                                \"accuracy\": 0,\n",
        "                                \"conciseness\": 0,\n",
        "                                \"source_attribution\": 0,\n",
        "                                \"reasonableness\": 0,\n",
        "                                \"composite\": 0\n",
        "                            }\n",
        "                        }\n",
        "\n",
        "                    # Add question evaluation\n",
        "                    formatted_evaluation[\"model_evaluations\"][model_name][\"thresholds\"][threshold][\"questions\"].append({\n",
        "                        \"question\": eval[\"question\"],\n",
        "                        \"scores\": eval[\"scores\"],\n",
        "                        \"composite_score\": eval.get(\"composite_score\", 0),\n",
        "                        \"explanation\": eval.get(\"explanation\", \"\")\n",
        "                    })\n",
        "\n",
        "                    # Update average scores\n",
        "                    questions = formatted_evaluation[\"model_evaluations\"][model_name][\"thresholds\"][threshold][\"questions\"]\n",
        "                    avg_scores = formatted_evaluation[\"model_evaluations\"][model_name][\"thresholds\"][threshold][\"average_scores\"]\n",
        "\n",
        "                    avg_scores[\"accuracy\"] = sum(q[\"scores\"][\"accuracy\"] for q in questions) / len(questions)\n",
        "                    avg_scores[\"conciseness\"] = sum(q[\"scores\"][\"conciseness\"] for q in questions) / len(questions)\n",
        "                    avg_scores[\"source_attribution\"] = sum(q[\"scores\"][\"source_attribution\"] for q in questions) / len(questions)\n",
        "                    avg_scores[\"reasonableness\"] = sum(q[\"scores\"][\"reasonableness\"] for q in questions) / len(questions)\n",
        "                    avg_scores[\"composite\"] = sum(q[\"composite_score\"] for q in questions) / len(questions)\n",
        "\n",
        "            # Save formatted results\n",
        "            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "            experiment_file = f\"{save_dir}/experiment_results_{timestamp}.json\"\n",
        "            evaluation_file = f\"{save_dir}/evaluation_results_{timestamp}.json\"\n",
        "\n",
        "            with open(experiment_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(formatted_experiment, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            with open(evaluation_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(formatted_evaluation, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            print(\"\\n=== Results Formatting Complete ===\")\n",
        "            return formatted_experiment, formatted_evaluation\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError in formatting and saving results: {str(e)}\")\n",
        "            default_eval = self._create_default_evaluation(experiment_results)\n",
        "            return experiment_results, default_eval\n",
        "\n",
        "    def evaluate_and_format(self, experiment_results: Dict, source_doc: str) -> Dict:\n",
        "        \"\"\"Convenience method for evaluation and formatting\"\"\"\n",
        "        print(\"\\n=== Starting evaluate_and_format ===\")\n",
        "        print(\"Step 1: Running evaluation\")\n",
        "        evaluation = self.evaluate_experiments(experiment_results, source_doc)\n",
        "\n",
        "        print(\"\\nStep 2: Running display_results\")\n",
        "        self.display_results(evaluation)\n",
        "\n",
        "        print(\"\\nStep 3: Returning evaluation\")\n",
        "        return evaluation\n",
        "\n",
        "\n",
        "    def display_results(self, evaluation_results: Dict = None):\n",
        "            \"\"\"Format and display evaluation results\"\"\"\n",
        "            try:\n",
        "                results = evaluation_results\n",
        "\n",
        "                print(\"\\n\" + \"=\"*80)\n",
        "                print(\"MODEL EVALUATION RESULTS\")\n",
        "                print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "                if \"evaluations\" in results:\n",
        "                    print(\"DETAILED MODEL PERFORMANCE\")\n",
        "                    print(\"-\"*80)\n",
        "                    current_model = None\n",
        "                    current_threshold = None\n",
        "\n",
        "                    # Sort evaluations by model, threshold, then question\n",
        "                    sorted_evaluations = sorted(\n",
        "                        results[\"evaluations\"],\n",
        "                        key=lambda x: (x[\"model\"], x[\"threshold\"], x[\"question\"])\n",
        "                    )\n",
        "\n",
        "                    for eval in sorted_evaluations:\n",
        "                        # Print model header if it's a new model\n",
        "                        if eval[\"model\"] != current_model:\n",
        "                            current_model = eval[\"model\"]\n",
        "                            print(f\"\\nModel: {current_model}\")\n",
        "                            current_threshold = None\n",
        "\n",
        "                        # Print threshold header if it's a new threshold\n",
        "                        if eval[\"threshold\"] != current_threshold:\n",
        "                            current_threshold = eval[\"threshold\"]\n",
        "                            print(f\"\\nThreshold: {current_threshold}\")\n",
        "                            print(\"─\"*40)\n",
        "\n",
        "                        # Print evaluation details\n",
        "                        print(f\"\\nQuestion: {eval['question']}\")\n",
        "                        print(f\"Accuracy Score:          {eval['scores']['accuracy']:>3}/100\")\n",
        "                        print(f\"Conciseness Score:       {eval['scores']['conciseness']:>3}/100\")\n",
        "                        print(f\"Source Attribution:      {eval['scores']['source_attribution']:>3}/100\")\n",
        "                        print(f\"Reasonableness Score:    {eval['scores']['reasonableness']:>3}/100\")\n",
        "                        print(f\"Final Composite Score:   {eval['composite_score']:>3}/100\")\n",
        "                        print(\"\\nExplanation:\")\n",
        "                        print(textwrap.fill(eval['explanation'], width=80))\n",
        "\n",
        "                # Print summary section\n",
        "                print(\"\\n\" + \"=\"*80)\n",
        "                print(\"OVERALL ANALYSIS\")\n",
        "                print(\"=\"*80)\n",
        "\n",
        "                if \"summary\" in results:\n",
        "                    print(\"\\nPerformance Summary:\")\n",
        "                    print(\"-\"*80)\n",
        "                    print(textwrap.fill(results[\"summary\"][\"overall_performance\"], width=80))\n",
        "\n",
        "                    print(\"\\nOptimal Configuration:\")\n",
        "                    print(\"-\"*80)\n",
        "                    print(textwrap.fill(results[\"summary\"][\"optimal_permutation\"], width=80))\n",
        "\n",
        "                    print(\"\\nPerformance Analysis:\")\n",
        "                    print(\"-\"*80)\n",
        "                    print(textwrap.fill(results[\"summary\"][\"performance_analysis\"], width=80))\n",
        "\n",
        "                # Print metadata\n",
        "                if \"metadata\" in results:\n",
        "                    print(\"\\n\" + \"=\"*80)\n",
        "                    print(\"METADATA\")\n",
        "                    print(\"=\"*80)\n",
        "                    print(f\"Timestamp:           {results['metadata']['timestamp']}\")\n",
        "                    print(f\"Model Used:          {results['metadata']['model_used']}\")\n",
        "                    print(f\"Permutations:        {results['metadata']['num_permutations_evaluated']}\")\n",
        "                    print(f\"Questions Evaluated: {results['metadata']['num_questions_evaluated']}\")\n",
        "                    print(f\"Evaluation Status:   {results['metadata']['evaluation_status']}\")\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(\"Error parsing JSON results:\", e)\n",
        "            except KeyError as e:\n",
        "                print(\"Error accessing result data:\", e)\n",
        "            except Exception as e:\n",
        "                print(f\"Error displaying results: {str(e)}\")"
      ],
      "metadata": {
        "id": "1rAK93yw4qCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "koQ5ZObJC2ek"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f825d4b647e54baf8cc941915977c208",
            "5cfa4d13782743699367b5cb85f92719",
            "c2de79c661bf4e4ba96614d573119025",
            "b0f1e9d58165488a942813b3633b1e1b",
            "42ae99323ec846df9d7c460122045c0b",
            "5fa091ab2c36459ab6c47eb8269342c4",
            "eb695ffc45e141ddba3a64a9d59cf2a7",
            "b44c4bd5290a46bc9861ab6d225ba42b",
            "be6fedbee2504f4c82aa037cd8b162a7",
            "4fdb63f390c84567b3d2d32c2195035c",
            "5a67f0a69b7746abab29bdd8606bcb52",
            "6456f4ecd4464d3fa6d16f0692cb82e2",
            "9ad062bc372b430c98b67a0c1fe218be",
            "af4094bcae3c42e189b557b892eaa2d3",
            "17d5f586fe7741fa8bfae4e7d33506f4",
            "d1356d2945e544b88d40696ffbc19e3e",
            "104c61ff60214ef0acc1e2d756ee6741",
            "1dc5ef188c594914bfb29a6de98f795e",
            "0a048f6b28d941798f34a0391a9fee35",
            "67395a76a4ea429982b376417029dfc5",
            "50a80bcce21048cb8e1c30d08627bf61",
            "c516403c73a2455fa2f7b7ac20741a68",
            "5539abc9d1df4042a7e6376aae0921e9",
            "27c21fe88f03445cb61fea1ce4236f34",
            "3fabcae387fe4dd8a09b0578f1216e66",
            "bdbc1d5f1b9849c085f0481186143e1a",
            "7b1a9379c3934807bef41559424b65fc",
            "76d1d067648b460fbeff269b44afd243",
            "bb0aedd53a5c479daf0ee3cba5e92965",
            "1676e313e03c44d38cf9ad03df66d401",
            "0bf76da9a2864cc4a0a8cf90cc1731dd",
            "82b9f784f63d4c349046e813dc338674",
            "331b13ca72784713bca655f73e00804a",
            "bfa7eae7e8c949d8b34519b8c42ff436",
            "d1a820ce638143a7a3880a32ed299a32",
            "eff5891f34224f51a24a0d860964a9b0",
            "b0cecf0191764ff29671cdaa92b587ce",
            "905cdc8745a64927a8bf1854fc20aa4b",
            "1f1a40bd62c74097a1fd71d991e6f826",
            "6296070c73024432a601d09995c6d0dc",
            "de03259ecf254daebae5b60c188acff7",
            "fcb2d405c53542ba9fbf14f41b14f163",
            "43ea9c9c056e4eb09d35e43909275aea",
            "65e9cdbb78f04968ab7faeaa736fa373",
            "a5db1db0e85145d5aabd66d30ab1152f",
            "63f7cb32892844eaa732a331bc872e0a",
            "5aa879bb90d74fc191549bc602b6a506",
            "0931ef9366b64208af98263be3e61614",
            "133f3b741f9e491f8ba7a0f3aa6a5a75",
            "14dae34c876e472d9f009956c8e054f6",
            "f1424427bb514a599ccee6c38e98beb0",
            "ea4130b8d4414427bd0c0a506468cda6",
            "4a1a1e85dd6946269a97013b81a3a31c",
            "66b51768f0fe4e7087d0014045601fc3",
            "16a08462a353482c808bb596367ca2d0",
            "5ba38fc2fe7b4c6990808f5e587dd8cd",
            "7c2514a89d39414f8fc6ae60a960d63f",
            "5d79008cac23434bb7e6eaac60080790",
            "7b5f947b3f084d16b49d36e3aac859c4",
            "94110fd58e9040d9ad8848e3b04957b7",
            "01202b48d5fd4437b7eb4ad33ed70850",
            "609014a40c47406e9aae25f85cf77827",
            "cf640736d8094b1cae434a65e12869ce",
            "a7bc5538ff624311ae1f21cc5833c455",
            "9d8836f6d7434691905cd593f1ba5436",
            "be58d3b23f6d4ce6b28283299dbc7f2e",
            "01c984c60fbb4cd3955221dc472281e5",
            "ce7a7421c4dd4487a994e863f7b6a7a0",
            "8114acee07c841bbb0b4f1589d088ea1",
            "96e9f5cbd20040768621c3eee864337a",
            "cd4e280721e848029d012897d59e8df9",
            "c8563182e4d447a3adc8c04c102ccd7d",
            "8cf252cd2b364c35bf6dff2edf271b6f",
            "789cde0c43384b7bb137f45396fb6e0e",
            "8834acf3899442f1a491719c7dcd8f3f",
            "2dd4d0a5d45a48f7a4c3704eb2a594c4",
            "fe66a088e1924b2e85269c7b8cedc415",
            "67ba24e0cc524b6fbf445dfb59465162",
            "bebfba2393c24bbc9da6b8998f96b29b",
            "75e2d67ec9204d438fe85c29c3ece3af",
            "dcbd36e1bb054c379fbee3ba7a51064c",
            "02e00a11d1204bfd92f3b820a0c746e8",
            "8a31fd1d31524ca88e523faba1e8535f",
            "70ddbc247234465f99564714d13ac9ae",
            "2a3bef29980945b6a1e9b4482b45d0a8",
            "07634d29e8914db98f531caea74f61f5",
            "00a61525e5634d449e67101bf73207c3",
            "6781fb91808f46318283a9b72537a78f",
            "3d96b00ac72841f594def3eac6372d34",
            "6056d7dd959e4605ac396ef45841cae8",
            "c804bb443961499d9ff9fd1840134904",
            "76de4172fd304d6fabe728e82639dc73",
            "3ff374f6d53c489697bde39581d48c27",
            "1b289b40b5da49d88b6b237f27dc9e49",
            "a0a57a5625f04080b640f6e70adab9b2",
            "9c5aba850d694a08af45ee00387e8baa",
            "8fca98db2e294448a19d776449d7bbf1",
            "3d218815b95a45ae8b706444e4e42e65",
            "385972638aac4147a122266b0ea93104",
            "cddd73b3f4f54a3cac61b652ecbfc971",
            "9bec88fe0b104c71b8df258c0e54641a",
            "8540888f5c764e10be42b40323826fbd",
            "590bae9821c546429d4f5420ab5b4f5e",
            "465d324716d54bdc92fc045e29970a8a",
            "47de4d9176e94fe2acf87110f6d08158",
            "b7a0486e92a54cabb004d373125f9cec",
            "d1b14f29795844d1ba4fd17898469104",
            "501d0caf642349eb9adb209a613ba1ab",
            "9ec5a04d05314329aba75ff6a4a957a2",
            "796d3ae309534d0690de3bb6030ecdcf",
            "68358064dace4c55819db0921ba4d9f9",
            "30fcecb9123c41b09e1e8897776d1a74",
            "b6ea5717c1c74da4a7f3fc456faf7b43",
            "46db7854b4fb4953b80f9c30f275ae3d",
            "86c9a32dcde74aefa5456ca792db0d4c",
            "67067f26dd9c4962ab37e2d957a22796",
            "4a006c2529df4b07be8b9dd26d544223",
            "ef9d38fe4e354042ae984fc52d76fbf0",
            "9407fa28625f4cab8ffbd375bda9ee19",
            "5175b519445c47678b8ada5792e9f215",
            "67c2aeb440604b488601b2c28cde4952"
          ]
        },
        "id": "6qdI5iaXYsun",
        "outputId": "ef748b21-af40-42eb-927d-14f1bd4af546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing global RAG pipeline\n",
            "Starting experiment with configurations:\n",
            "Global temperature: 0.3\n",
            "Models: ['open-mistral-nemo', 'ministral-8b-latest', 'wjleece/quantized-mistral-nemo-12b']\n",
            "Thresholds: [85, 95]\n",
            "Number of questions: 5\n",
            "\n",
            "Processing threshold: 85\n",
            "Creating new semantic chunks for threshold 85\n",
            "\n",
            "Testing model: open-mistral-nemo\n",
            "Processing question: What were cloud revenues in Q2 2024?\n",
            "Processing question: What were the main drivers of revenue growth in Q2?\n",
            "Processing question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Processing question: Can you summarize recent key antitrust matters?\n",
            "Processing question: What were YouTube ad revenues in Q2?\n",
            "\n",
            "Testing model: ministral-8b-latest\n",
            "Processing question: What were cloud revenues in Q2 2024?\n",
            "Processing question: What were the main drivers of revenue growth in Q2?\n",
            "Processing question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Processing question: Can you summarize recent key antitrust matters?\n",
            "Processing question: What were YouTube ad revenues in Q2?\n",
            "\n",
            "Testing model: wjleece/quantized-mistral-nemo-12b\n",
            "Loading quantized model: wjleece/quantized-mistral-nemo-12b\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/181k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f825d4b647e54baf8cc941915977c208"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.26M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6456f4ecd4464d3fa6d16f0692cb82e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5539abc9d1df4042a7e6376aae0921e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfa7eae7e8c949d8b34519b8c42ff436"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/111k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5db1db0e85145d5aabd66d30ab1152f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ba38fc2fe7b4c6990808f5e587dd8cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01c984c60fbb4cd3955221dc472281e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.84G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67ba24e0cc524b6fbf445dfb59465162"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d96b00ac72841f594def3eac6372d34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cddd73b3f4f54a3cac61b652ecbfc971"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: What were cloud revenues in Q2 2024?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-dcdddbfb2e81>:151: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = llm(formatted_prompt)\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: What were the main drivers of revenue growth in Q2?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: How much did YouTube ad revenues grow in Q2 in APAC?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: Can you summarize recent key antitrust matters?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: What were YouTube ad revenues in Q2?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing threshold: 95\n",
            "Creating new semantic chunks for threshold 95\n",
            "\n",
            "Testing model: open-mistral-nemo\n",
            "Processing question: What were cloud revenues in Q2 2024?\n",
            "Processing question: What were the main drivers of revenue growth in Q2?\n",
            "Processing question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Processing question: Can you summarize recent key antitrust matters?\n",
            "Processing question: What were YouTube ad revenues in Q2?\n",
            "\n",
            "Testing model: ministral-8b-latest\n",
            "Processing question: What were cloud revenues in Q2 2024?\n",
            "Processing question: What were the main drivers of revenue growth in Q2?\n",
            "Processing question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Processing question: Can you summarize recent key antitrust matters?\n",
            "Processing question: What were YouTube ad revenues in Q2?\n",
            "\n",
            "Testing model: wjleece/quantized-mistral-nemo-12b\n",
            "Loading quantized model: wjleece/quantized-mistral-nemo-12b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68358064dace4c55819db0921ba4d9f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: What were cloud revenues in Q2 2024?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: What were the main drivers of revenue growth in Q2?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: How much did YouTube ad revenues grow in Q2 in APAC?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: Can you summarize recent key antitrust matters?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing question: What were YouTube ad revenues in Q2?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initializing GPT-4 evaluation...\n",
            "\n",
            "=== Starting evaluate_and_format ===\n",
            "Step 1: Running evaluation\n",
            "\n",
            "=== Starting Evaluation Process ===\n",
            "Number of unique questions to evaluate: 5\n",
            "Number of model/threshold combinations: 6\n",
            "\n",
            "--- Getting Baseline Answers ---\n",
            "Baseline response received: ```json\n",
            "{\n",
            "    \"What were YouTube ad revenues in Q2?\": \"Information not provided in the source document.\",\n",
            "    \"How much did YouTube ad revenues grow in Q2 in APAC?\": \"Information not provided in the s...\n",
            "Baseline answers received\n",
            "\n",
            "Evaluating model: ministral-8b-latest, threshold: 95\n",
            "\n",
            "Evaluating ministral-8b-latest/95/What were cloud revenues in Q2 2024?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were cloud revenues in Q2 2024?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 0,\n",
            "        \"conciseness\": 80,\n",
            "        \"so...\n",
            "\n",
            "Evaluating ministral-8b-latest/95/What were the main drivers of revenue growth in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were the main drivers of revenue growth in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 100,\n",
            "        \"conciseness\"...\n",
            "\n",
            "Evaluating ministral-8b-latest/95/How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"How much did YouTube ad revenues grow in Q2 in APAC?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 60,\n",
            "        \"conciseness\"...\n",
            "\n",
            "Evaluating ministral-8b-latest/95/Can you summarize recent key antitrust matters?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"Can you summarize recent key antitrust matters?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 70,\n",
            "        \"conciseness\": 75,...\n",
            "\n",
            "Evaluating ministral-8b-latest/95/What were YouTube ad revenues in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were YouTube ad revenues in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 40,\n",
            "        \"conciseness\": 90,\n",
            "        \"s...\n",
            "\n",
            "Evaluating model: ministral-8b-latest, threshold: 85\n",
            "\n",
            "Evaluating ministral-8b-latest/85/What were cloud revenues in Q2 2024?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were cloud revenues in Q2 2024?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 50,\n",
            "        \"conciseness\": 75,\n",
            "        \"s...\n",
            "\n",
            "Evaluating ministral-8b-latest/85/What were the main drivers of revenue growth in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were the main drivers of revenue growth in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 90,\n",
            "        \"conciseness\":...\n",
            "\n",
            "Evaluating ministral-8b-latest/85/How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"How much did YouTube ad revenues grow in Q2 in APAC?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 60,\n",
            "        \"conciseness\"...\n",
            "\n",
            "Evaluating ministral-8b-latest/85/Can you summarize recent key antitrust matters?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"Can you summarize recent key antitrust matters?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 90,\n",
            "        \"conciseness\": 85,...\n",
            "\n",
            "Evaluating ministral-8b-latest/85/What were YouTube ad revenues in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"ministral-8b-latest\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were YouTube ad revenues in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 50,\n",
            "        \"conciseness\": 90,\n",
            "        \"s...\n",
            "\n",
            "Evaluating model: wjleece/quantized-mistral-nemo-12b, threshold: 95\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/95/What were cloud revenues in Q2 2024?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were cloud revenues in Q2 2024?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 100,\n",
            "        \"conciseness\"...\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/95/What were the main drivers of revenue growth in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were the main drivers of revenue growth in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 100,\n",
            "      ...\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/95/How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"How much did YouTube ad revenues grow in Q2 in APAC?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 50,\n",
            "      ...\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/95/Can you summarize recent key antitrust matters?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"Can you summarize recent key antitrust matters?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 90,\n",
            "        \"co...\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/95/What were YouTube ad revenues in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were YouTube ad revenues in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 50,\n",
            "        \"conciseness\":...\n",
            "\n",
            "Evaluating model: open-mistral-nemo, threshold: 95\n",
            "\n",
            "Evaluating open-mistral-nemo/95/What were cloud revenues in Q2 2024?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were cloud revenues in Q2 2024?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 100,\n",
            "        \"conciseness\": 100,\n",
            "        \"s...\n",
            "\n",
            "Evaluating open-mistral-nemo/95/What were the main drivers of revenue growth in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were the main drivers of revenue growth in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 100,\n",
            "        \"conciseness\": ...\n",
            "\n",
            "Evaluating open-mistral-nemo/95/How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"How much did YouTube ad revenues grow in Q2 in APAC?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 50,\n",
            "        \"conciseness\": ...\n",
            "\n",
            "Evaluating open-mistral-nemo/95/Can you summarize recent key antitrust matters?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"Can you summarize recent key antitrust matters?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 90,\n",
            "        \"conciseness\": 85,\n",
            " ...\n",
            "\n",
            "Evaluating open-mistral-nemo/95/What were YouTube ad revenues in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 95,\n",
            "    \"question\": \"What were YouTube ad revenues in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 100,\n",
            "        \"conciseness\": 100,\n",
            "        \"s...\n",
            "\n",
            "Evaluating model: wjleece/quantized-mistral-nemo-12b, threshold: 85\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/85/What were cloud revenues in Q2 2024?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were cloud revenues in Q2 2024?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 0,\n",
            "        \"conciseness\": ...\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/85/What were the main drivers of revenue growth in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were the main drivers of revenue growth in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 90,\n",
            "       ...\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/85/How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"How much did YouTube ad revenues grow in Q2 in APAC?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 20,\n",
            "      ...\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/85/Can you summarize recent key antitrust matters?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"Can you summarize recent key antitrust matters?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 95,\n",
            "        \"co...\n",
            "\n",
            "Evaluating wjleece/quantized-mistral-nemo-12b/85/What were YouTube ad revenues in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"wjleece/quantized-mistral-nemo-12b\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were YouTube ad revenues in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 20,\n",
            "        \"conciseness\":...\n",
            "\n",
            "Evaluating model: open-mistral-nemo, threshold: 85\n",
            "\n",
            "Evaluating open-mistral-nemo/85/What were cloud revenues in Q2 2024?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were cloud revenues in Q2 2024?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 50,\n",
            "        \"conciseness\": 90,\n",
            "        \"sou...\n",
            "\n",
            "Evaluating open-mistral-nemo/85/What were the main drivers of revenue growth in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were the main drivers of revenue growth in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 80,\n",
            "        \"conciseness\": 9...\n",
            "\n",
            "Evaluating open-mistral-nemo/85/How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"How much did YouTube ad revenues grow in Q2 in APAC?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 60,\n",
            "        \"conciseness\": ...\n",
            "\n",
            "Evaluating open-mistral-nemo/85/Can you summarize recent key antitrust matters?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"Can you summarize recent key antitrust matters?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 90,\n",
            "        \"conciseness\": 85,\n",
            " ...\n",
            "\n",
            "Evaluating open-mistral-nemo/85/What were YouTube ad revenues in Q2?\n",
            "Raw response: ```json\n",
            "{\n",
            "    \"model\": \"open-mistral-nemo\",\n",
            "    \"threshold\": 85,\n",
            "    \"question\": \"What were YouTube ad revenues in Q2?\",\n",
            "    \"scores\": {\n",
            "        \"accuracy\": 50,\n",
            "        \"conciseness\": 90,\n",
            "        \"sou...\n",
            "\n",
            "Step 2: Running display_results\n",
            "\n",
            "================================================================================\n",
            "MODEL EVALUATION RESULTS\n",
            "================================================================================\n",
            "\n",
            "DETAILED MODEL PERFORMANCE\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Model: ministral-8b-latest\n",
            "\n",
            "Threshold: 85\n",
            "────────────────────────────────────────\n",
            "\n",
            "Question: Can you summarize recent key antitrust matters?\n",
            "Accuracy Score:           90/100\n",
            "Conciseness Score:        85/100\n",
            "Source Attribution:       95/100\n",
            "Reasonableness Score:     90/100\n",
            "Final Composite Score:    90/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately summarizes key antitrust matters involving Google,\n",
            "matching the source content well. It is concise, listing only relevant events\n",
            "without unnecessary details, although it could be slightly more succinct. Source\n",
            "attribution is excellent, directly referring to specific information from the\n",
            "source text, ensuring that the summary is grounded in the provided data. The\n",
            "response is reasonable and properly contextualized, covering a series of\n",
            "significant events from 2010 to 2022, which are relevant to the question about\n",
            "recent antitrust matters.\n",
            "\n",
            "Question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Accuracy Score:           60/100\n",
            "Conciseness Score:        80/100\n",
            "Source Attribution:       70/100\n",
            "Reasonableness Score:     50/100\n",
            "Final Composite Score:    65/100\n",
            "\n",
            "Explanation:\n",
            "The response provides a figure for YouTube ad revenue growth, but it does not\n",
            "specify the APAC region, which is crucial for accuracy given the context of the\n",
            "question. The baseline indicates that the source document did not provide this\n",
            "specific information for APAC. The response lacks explicit mention of APAC, thus\n",
            "failing to directly address the question's regional specificity. While the\n",
            "response is concise and uses a source, the calculation seems slightly off due to\n",
            "misinterpretation of the source data, as it mentions a $998 million increase\n",
            "rather than $1,000 million. The reasonableness is low due to the incorrect\n",
            "application of global data to a regional context.\n",
            "\n",
            "Question: What were YouTube ad revenues in Q2?\n",
            "Accuracy Score:           50/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       40/100\n",
            "Reasonableness Score:     60/100\n",
            "Final Composite Score:    60/100\n",
            "\n",
            "Explanation:\n",
            "The response claims that YouTube ad revenues in Q2 were $8,663 million, but this\n",
            "specific figure is not directly supported by the provided source. The source\n",
            "only mentions the increase in revenues over a period, not the actual revenue\n",
            "figure for Q2. Therefore, the accuracy is low as the answer is not substantiated\n",
            "by the source. The response is concise, providing a direct answer without\n",
            "unnecessary information, hence the high conciseness score. However, the source\n",
            "attribution is poor because the response does not accurately use the provided\n",
            "source text as evidence. The reasonableness score is low because the calculation\n",
            "or derivation of the mentioned revenue figure from the provided data is not\n",
            "clear, making the response lack proper context.\n",
            "\n",
            "Question: What were cloud revenues in Q2 2024?\n",
            "Accuracy Score:           50/100\n",
            "Conciseness Score:        75/100\n",
            "Source Attribution:       60/100\n",
            "Reasonableness Score:     70/100\n",
            "Final Composite Score:   63.75/100\n",
            "\n",
            "Explanation:\n",
            "The response states that Google Cloud revenues increased by $2.3 billion from Q2\n",
            "2023 to Q2 2024, but it does not provide the actual revenue figures for Q2 2024,\n",
            "which is what the question asks. Therefore, it only partially answers the\n",
            "question, affecting accuracy. The response is concise, providing a direct\n",
            "statement, but it lacks the actual revenue figure. The source attribution is\n",
            "somewhat relevant as it cites a source that mentions the increase, but not the\n",
            "exact revenue numbers. Finally, the reasonableness is moderate as the answer\n",
            "does provide some context about the revenue increase but fails to address the\n",
            "exact question asked.\n",
            "\n",
            "Question: What were the main drivers of revenue growth in Q2?\n",
            "Accuracy Score:           90/100\n",
            "Conciseness Score:        95/100\n",
            "Source Attribution:       90/100\n",
            "Reasonableness Score:     90/100\n",
            "Final Composite Score:   91.25/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately identifies the main drivers of revenue growth in Q2 as\n",
            "increases in subscription revenues and Google Cloud revenues, which align with\n",
            "the provided source texts. The answer is concise, directly addressing the\n",
            "question without unnecessary details. The source attribution is strong, as the\n",
            "response draws specifically from the relevant parts of the source documents.\n",
            "Additionally, the response is reasonable and well-contextualized, clearly\n",
            "linking the growth drivers to the revenue increase in Q2. Overall, the response\n",
            "meets the threshold for quality with a high composite score.\n",
            "\n",
            "Threshold: 95\n",
            "────────────────────────────────────────\n",
            "\n",
            "Question: Can you summarize recent key antitrust matters?\n",
            "Accuracy Score:           70/100\n",
            "Conciseness Score:        75/100\n",
            "Source Attribution:       50/100\n",
            "Reasonableness Score:     80/100\n",
            "Final Composite Score:   68.75/100\n",
            "\n",
            "Explanation:\n",
            "The response provides details on several antitrust matters involving Google,\n",
            "which are relevant to the question. However, the inclusion of events from 2017\n",
            "and 2018, while accurate, may not qualify as 'recent' given the context of the\n",
            "question. The response does not clearly distinguish between past events and\n",
            "ongoing or very recent matters. While it presents information succinctly, it\n",
            "lacks precise alignment with the source document, especially since the baseline\n",
            "answer indicates that this specific information was not provided in the source.\n",
            "This affects both accuracy and source attribution scores. Additionally, the\n",
            "response could have been more concise by focusing only on the most recent\n",
            "developments. Overall, the response is somewhat reasonable in presenting the\n",
            "information but does not fully meet the criteria for accuracy and source\n",
            "attribution.\n",
            "\n",
            "Question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Accuracy Score:           60/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       50/100\n",
            "Reasonableness Score:     65/100\n",
            "Final Composite Score:   66.25/100\n",
            "\n",
            "Explanation:\n",
            "The response claims that YouTube ad revenues grew by $998 million in Q2 in APAC.\n",
            "However, the source text does not specify the APAC region or isolate the growth\n",
            "to Q2 alone. It mentions a $998 million increase in YouTube ad revenues over a\n",
            "certain period but does not attribute this specifically to the APAC region.\n",
            "Therefore, the accuracy is low at 60. The response is concise, directly\n",
            "providing an answer with minimal extra information, earning a conciseness score\n",
            "of 90. Source attribution is poor because the source does not precisely support\n",
            "the claim about APAC, scoring 50. The reasonableness score is 65 due to the lack\n",
            "of regional context in the answer, leading to potential misinterpretation.\n",
            "\n",
            "Question: What were YouTube ad revenues in Q2?\n",
            "Accuracy Score:           40/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       30/100\n",
            "Reasonableness Score:     50/100\n",
            "Final Composite Score:   52.5/100\n",
            "\n",
            "Explanation:\n",
            "The accuracy of the response is low because the provided figure of $8,663\n",
            "million for Q2 2024 YouTube ad revenues is not directly supported by the source\n",
            "text. The source mentions an increase of $998 million from Q2 2023 to Q2 2024,\n",
            "but does not provide the actual revenue figures for these periods. Conciseness\n",
            "is high as the response directly answers the question without unnecessary\n",
            "details. Source attribution is poor because the response does not directly use\n",
            "the source text to derive the final revenue figure; it assumes a base figure\n",
            "that the source does not provide. Reasonableness is moderate because the answer\n",
            "is not properly contextualized within the information given, leading to an\n",
            "unsupported conclusion.\n",
            "\n",
            "Question: What were cloud revenues in Q2 2024?\n",
            "Accuracy Score:            0/100\n",
            "Conciseness Score:        80/100\n",
            "Source Attribution:        0/100\n",
            "Reasonableness Score:     50/100\n",
            "Final Composite Score:   32.5/100\n",
            "\n",
            "Explanation:\n",
            "The response claims that Google Cloud revenues were $10.3 billion in Q2 2024,\n",
            "but the provided source does not contain this specific information. Instead, the\n",
            "source only discusses the increase in revenues without stating an absolute\n",
            "figure for Q2 2024. Therefore, the accuracy and source attribution scores are 0\n",
            "because the response does not align with the source. The conciseness score is\n",
            "relatively high as the response is clear and direct, but it includes information\n",
            "not supported by the source. The reasonableness score is low because the\n",
            "response fails to contextualize the information correctly based on the available\n",
            "data.\n",
            "\n",
            "Question: What were the main drivers of revenue growth in Q2?\n",
            "Accuracy Score:          100/100\n",
            "Conciseness Score:       100/100\n",
            "Source Attribution:      100/100\n",
            "Reasonableness Score:    100/100\n",
            "Final Composite Score:   100/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately reflects the information provided in the source\n",
            "document, stating the main drivers of revenue growth in Q2 as an increase in\n",
            "Google Services and Google Cloud revenues. The response is concise, focusing\n",
            "directly on the key drivers without unnecessary details. It appropriately uses\n",
            "the relevant source text as evidence, and the answer is well-contextualized for\n",
            "the question asked. Thus, it meets all criteria perfectly.\n",
            "\n",
            "Model: open-mistral-nemo\n",
            "\n",
            "Threshold: 85\n",
            "────────────────────────────────────────\n",
            "\n",
            "Question: Can you summarize recent key antitrust matters?\n",
            "Accuracy Score:           90/100\n",
            "Conciseness Score:        85/100\n",
            "Source Attribution:       90/100\n",
            "Reasonableness Score:     88/100\n",
            "Final Composite Score:   88.25/100\n",
            "\n",
            "Explanation:\n",
            "The response provides a well-summarized list of recent key antitrust matters\n",
            "related to Google, reflecting the information from the sources. Each point in\n",
            "the response is backed by the given sources, ensuring high accuracy and proper\n",
            "source attribution. The response is concise, listing the matters without\n",
            "unnecessary information, though it could be slightly more succinct. It is\n",
            "reasonable and well-contextualized, as it focuses on significant antitrust\n",
            "issues relevant to the question. Overall, the response meets the threshold with\n",
            "a composite score of 88.25.\n",
            "\n",
            "Question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Accuracy Score:           60/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       50/100\n",
            "Reasonableness Score:     70/100\n",
            "Final Composite Score:   67.5/100\n",
            "\n",
            "Explanation:\n",
            "The response states that YouTube ad revenues grew by $2.1 billion, but the\n",
            "source provided does not specify growth in APAC, nor does it mention a $2.1\n",
            "billion figure. The source mentions a $998 million increase for the three months\n",
            "in 2024 compared to 2023, which could relate to global figures, not specifically\n",
            "APAC. Therefore, the accuracy and source attribution scores are low. The\n",
            "response is concise, as it directly answers the question without additional\n",
            "information. However, the reasonableness score is moderate as the answer lacks\n",
            "proper context regarding the APAC region.\n",
            "\n",
            "Question: What were YouTube ad revenues in Q2?\n",
            "Accuracy Score:           50/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       60/100\n",
            "Reasonableness Score:     60/100\n",
            "Final Composite Score:    65/100\n",
            "\n",
            "Explanation:\n",
            "The response states that YouTube ad revenues in Q2 were $8,663 million, which\n",
            "matches one of the figures provided in the source. However, the source provides\n",
            "two figures for different years, and the response does not specify which year it\n",
            "is referring to. This ambiguity affects the accuracy and reasonableness of the\n",
            "response. The answer is concise, providing the requested information without\n",
            "additional context. Source attribution is partially met as the response uses a\n",
            "number found in the source, but fails to clarify the year, reducing its\n",
            "effectiveness. Overall, the response lacks specificity and context, impacting\n",
            "its accuracy and overall quality.\n",
            "\n",
            "Question: What were cloud revenues in Q2 2024?\n",
            "Accuracy Score:           50/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       70/100\n",
            "Reasonableness Score:     60/100\n",
            "Final Composite Score:   67.5/100\n",
            "\n",
            "Explanation:\n",
            "The response provides a specific figure for Google Cloud revenues in Q2 2024,\n",
            "which is not directly confirmed by the baseline or the provided source\n",
            "information. The source mentions revenues for 2024 in general, without\n",
            "specifying Q2. Conciseness is high because the answer is clear and direct.\n",
            "Source attribution is moderate, as the source is relevant but lacks specific\n",
            "detail about Q2. Reasonableness is moderate because while the answer seems\n",
            "plausible, it lacks specific contextual confirmation from the source.\n",
            "\n",
            "Question: What were the main drivers of revenue growth in Q2?\n",
            "Accuracy Score:           80/100\n",
            "Conciseness Score:        95/100\n",
            "Source Attribution:       90/100\n",
            "Reasonableness Score:     85/100\n",
            "Final Composite Score:   87.5/100\n",
            "\n",
            "Explanation:\n",
            "The response provides a specific answer regarding the main drivers of revenue\n",
            "growth in Q2, focusing on an increase in subscription revenues from YouTube\n",
            "services. The answer is concise and directly addresses the question without\n",
            "unnecessary information. The source attribution score is high because the\n",
            "response includes a source that supports the information provided. However,\n",
            "while the response is reasonable and contextualized, it does not match the\n",
            "baseline answer, which stated that the information was not provided in the\n",
            "source document. This discrepancy results in a lower accuracy score.\n",
            "\n",
            "Threshold: 95\n",
            "────────────────────────────────────────\n",
            "\n",
            "Question: Can you summarize recent key antitrust matters?\n",
            "Accuracy Score:           90/100\n",
            "Conciseness Score:        85/100\n",
            "Source Attribution:       80/100\n",
            "Reasonableness Score:     90/100\n",
            "Final Composite Score:   86.25/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately summarizes several key antitrust matters involving\n",
            "Google, including fines and lawsuits in both the EU and the US. The events\n",
            "described are consistent with the sources provided, although the EU fines are\n",
            "not the most recent events, as they date back to 2017 and 2018. The response is\n",
            "concise in its summarization, but it could be slightly more concise by omitting\n",
            "specific amounts and focusing on the nature of the cases. The source attribution\n",
            "is somewhat lacking, as it does not directly reference the source documents or\n",
            "provide full context for the information. The reasonableness is high as the\n",
            "response provides a well-contextualized overview of the antitrust matters, but\n",
            "could be improved by stating the relevance of these events to the current\n",
            "antitrust landscape.\n",
            "\n",
            "Question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Accuracy Score:           50/100\n",
            "Conciseness Score:        80/100\n",
            "Source Attribution:       60/100\n",
            "Reasonableness Score:     40/100\n",
            "Final Composite Score:   57.5/100\n",
            "\n",
            "Explanation:\n",
            "The response claims that YouTube ad revenues grew by $998 million in Q2 in APAC.\n",
            "However, the source provided does not specifically mention APAC, and it's\n",
            "unclear if the $998 million figure pertains solely to that region or globally.\n",
            "Therefore, the accuracy is low as the response does not directly match the\n",
            "question's requirement for APAC-specific data. The conciseness is relatively\n",
            "high because the response is clear and without unnecessary information. Source\n",
            "attribution is low because the response does not accurately reflect the source\n",
            "text's specifics, particularly regarding the APAC region. Finally, the\n",
            "reasonableness score is low as the response lacks contextualization within the\n",
            "question's regional scope.\n",
            "\n",
            "Question: What were YouTube ad revenues in Q2?\n",
            "Accuracy Score:          100/100\n",
            "Conciseness Score:       100/100\n",
            "Source Attribution:      100/100\n",
            "Reasonableness Score:    100/100\n",
            "Final Composite Score:   100/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately states the YouTube ad revenues for Q2 as $8,663 million,\n",
            "which matches the information provided in the source. The answer is concise and\n",
            "directly addresses the question without including unnecessary information. The\n",
            "source attribution is clear and directly supports the response. The answer is\n",
            "reasonable as it fits the context of the question and the information given.\n",
            "\n",
            "Question: What were cloud revenues in Q2 2024?\n",
            "Accuracy Score:          100/100\n",
            "Conciseness Score:       100/100\n",
            "Source Attribution:      100/100\n",
            "Reasonableness Score:    100/100\n",
            "Final Composite Score:   100/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately states the Google Cloud revenues for Q2 2024 as $10.347\n",
            "billion, which matches the information provided in the source document. The\n",
            "response is concise, providing only the necessary information to answer the\n",
            "question. The source attribution is correct, with the relevant data clearly\n",
            "extracted from the source text provided. Additionally, the answer is reasonable\n",
            "as it directly addresses the question with appropriate context.\n",
            "\n",
            "Question: What were the main drivers of revenue growth in Q2?\n",
            "Accuracy Score:          100/100\n",
            "Conciseness Score:       100/100\n",
            "Source Attribution:      100/100\n",
            "Reasonableness Score:    100/100\n",
            "Final Composite Score:   100/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately reflects the information provided in the source\n",
            "document, citing the increase in Google Services and Google Cloud revenues as\n",
            "the main drivers of revenue growth in Q2. The response is concise, directly\n",
            "answering the question without unnecessary information. It includes relevant\n",
            "source text as evidence, ensuring that the details are supported by the provided\n",
            "data. The context is appropriately maintained, focusing on the specific revenue\n",
            "growth drivers mentioned in the source.\n",
            "\n",
            "Model: wjleece/quantized-mistral-nemo-12b\n",
            "\n",
            "Threshold: 85\n",
            "────────────────────────────────────────\n",
            "\n",
            "Question: Can you summarize recent key antitrust matters?\n",
            "Accuracy Score:           95/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       95/100\n",
            "Reasonableness Score:     90/100\n",
            "Final Composite Score:   92.5/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately summarizes the key antitrust matters mentioned in the\n",
            "source material, including Google's appeal against the EC's decision, the DOJ's\n",
            "civil investigative demands, and the lawsuit filed by the DOJ and state\n",
            "Attorneys General. The response is concise and does not include unnecessary\n",
            "information. It effectively uses relevant source text as evidence, aligning well\n",
            "with the provided sources. The answer is contextually appropriate, reflecting a\n",
            "sound understanding of the antitrust issues described in the sources.\n",
            "\n",
            "Question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Accuracy Score:           20/100\n",
            "Conciseness Score:        80/100\n",
            "Source Attribution:       10/100\n",
            "Reasonableness Score:     30/100\n",
            "Final Composite Score:    35/100\n",
            "\n",
            "Explanation:\n",
            "The response provided a specific figure of '$998 million' for YouTube ad revenue\n",
            "growth in Q2 in APAC, but the baseline answer indicated that this information\n",
            "was not provided in the source document. This results in a low accuracy score.\n",
            "The response is concise, directly providing an answer without extra information,\n",
            "which results in a higher conciseness score. However, the source attribution\n",
            "score is low because the source text provided does not substantiate the claim\n",
            "about APAC-specific growth. The reasonableness score is also low because there\n",
            "is no context or indication that the figure is relevant or accurate for the\n",
            "specific region (APAC) or time period (Q2). Overall, the answer does not align\n",
            "well with the provided source or the baseline answer.\n",
            "\n",
            "Question: What were YouTube ad revenues in Q2?\n",
            "Accuracy Score:           20/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       30/100\n",
            "Reasonableness Score:     40/100\n",
            "Final Composite Score:    45/100\n",
            "\n",
            "Explanation:\n",
            "The response provided an exact figure, $8.663 billion, for YouTube ad revenues\n",
            "in Q2, but this figure is not supported by the source. The source only mentions\n",
            "an increase in revenue of $998 million for the quarter, without providing an\n",
            "absolute revenue figure. Thus, the accuracy is low because the answer does not\n",
            "match the data available in the source. The response is concise since it\n",
            "directly answers the question without additional information, hence a high\n",
            "conciseness score. However, the source attribution score is low because the\n",
            "provided source does not actually contain the information needed to derive the\n",
            "answer given. The reasonableness score is low as well, as the figure mentioned\n",
            "is not properly contextualized given the source information, leading to\n",
            "potential confusion about the origin of the number provided.\n",
            "\n",
            "Question: What were cloud revenues in Q2 2024?\n",
            "Accuracy Score:            0/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:        0/100\n",
            "Reasonableness Score:     50/100\n",
            "Final Composite Score:    35/100\n",
            "\n",
            "Explanation:\n",
            "The response provides a specific figure of $10.3 billion for cloud revenues in\n",
            "Q2 2024. However, the baseline answer states that this information was not\n",
            "provided in the source document, indicating that the figure may be inaccurate or\n",
            "fabricated. Consequently, the accuracy score is 0. The response is concise,\n",
            "directly answering the question without unnecessary information, hence the\n",
            "conciseness score is 90. The source attribution score is 0 because the provided\n",
            "source does not substantiate the claim, as it is based on information not\n",
            "available in the source document. The reasonableness score is 50, as the answer\n",
            "appears contextually relevant but lacks validation from the source document.\n",
            "\n",
            "Question: What were the main drivers of revenue growth in Q2?\n",
            "Accuracy Score:           90/100\n",
            "Conciseness Score:        95/100\n",
            "Source Attribution:       85/100\n",
            "Reasonableness Score:     90/100\n",
            "Final Composite Score:    90/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately identifies the main drivers of revenue growth in Q2 as\n",
            "an increase in subscription revenues and the growth in paid subscribers for\n",
            "YouTube services, which matches the sources provided. The response is concise,\n",
            "directly answering the question without unnecessary information. It utilizes\n",
            "relevant source text to support its answer, although it could be slightly more\n",
            "explicit in linking the second source to the overall revenue growth context. The\n",
            "answer is reasonable, providing a clear and contextually appropriate explanation\n",
            "based on the information given in the sources.\n",
            "\n",
            "Threshold: 95\n",
            "────────────────────────────────────────\n",
            "\n",
            "Question: Can you summarize recent key antitrust matters?\n",
            "Accuracy Score:           90/100\n",
            "Conciseness Score:        85/100\n",
            "Source Attribution:       95/100\n",
            "Reasonableness Score:     90/100\n",
            "Final Composite Score:    90/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately summarizes recent key antitrust matters involving\n",
            "Google, referencing specific fines and legal actions, which align with the\n",
            "provided source text. The mention of Google's appeals and specific fines, as\n",
            "well as ongoing investigations by the EC, CMA, and ACCC, are factually correct\n",
            "and sourced appropriately. The response is concise, but could be slightly more\n",
            "focused to improve clarity. Source attribution is strong, as the response\n",
            "directly corresponds to the given source excerpts. The context is properly\n",
            "framed within the ongoing legal challenges and investigations, making the answer\n",
            "reasonable and well-contextualized. Overall, the response is accurate and aligns\n",
            "well with the source material, although slightly more succinct phrasing could\n",
            "enhance conciseness.\n",
            "\n",
            "Question: How much did YouTube ad revenues grow in Q2 in APAC?\n",
            "Accuracy Score:           50/100\n",
            "Conciseness Score:        80/100\n",
            "Source Attribution:       60/100\n",
            "Reasonableness Score:     40/100\n",
            "Final Composite Score:   57.5/100\n",
            "\n",
            "Explanation:\n",
            "The response states that YouTube ad revenues grew by $998 million in Q2 in APAC.\n",
            "However, the source text does not specify that this growth occurred specifically\n",
            "in the APAC region, which affects accuracy and reasonableness scores. The answer\n",
            "is concise, but it lacks proper context regarding the regional specificity,\n",
            "affecting the reasonableness. Source attribution is somewhat relevant as it uses\n",
            "numbers from the source, but it incorrectly applies them to a specific region\n",
            "not mentioned in the source.\n",
            "\n",
            "Question: What were YouTube ad revenues in Q2?\n",
            "Accuracy Score:           50/100\n",
            "Conciseness Score:        90/100\n",
            "Source Attribution:       40/100\n",
            "Reasonableness Score:     60/100\n",
            "Final Composite Score:    60/100\n",
            "\n",
            "Explanation:\n",
            "The model's response states that YouTube ad revenues in Q2 were $8.663 billion,\n",
            "but the provided source does not directly support this figure. The source only\n",
            "mentions an increase of $998 million in revenues for the quarter, without\n",
            "providing the total revenue amount. Therefore, the accuracy score is low because\n",
            "the specific figure mentioned is not verified by the source. The response is\n",
            "concise, as it directly addresses the question without extra information, hence\n",
            "a high conciseness score. However, the source attribution score is low because\n",
            "the source does not provide the exact revenue figure, making the attribution\n",
            "weak. The reasonableness score is moderate; although the answer is clear, it\n",
            "lacks proper contextual backing from the source data.\n",
            "\n",
            "Question: What were cloud revenues in Q2 2024?\n",
            "Accuracy Score:          100/100\n",
            "Conciseness Score:       100/100\n",
            "Source Attribution:      100/100\n",
            "Reasonableness Score:    100/100\n",
            "Final Composite Score:   100/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately reports the cloud revenues in Q2 2024 as $10.3 billion,\n",
            "which matches the information provided in the source. It presents the\n",
            "information concisely without extraneous details. The source attribution is\n",
            "direct and relevant, clearly justifying the answer. The response is reasonable\n",
            "and properly contextualized, as it directly addresses the question with the\n",
            "specific data point from the source.\n",
            "\n",
            "Question: What were the main drivers of revenue growth in Q2?\n",
            "Accuracy Score:          100/100\n",
            "Conciseness Score:       100/100\n",
            "Source Attribution:      100/100\n",
            "Reasonableness Score:    100/100\n",
            "Final Composite Score:   100/100\n",
            "\n",
            "Explanation:\n",
            "The response accurately identifies the main drivers of revenue growth in Q2 as\n",
            "increases in Google Services and Google Cloud revenues, matching the information\n",
            "provided in the source text. The response is concise, providing only the\n",
            "necessary details without extraneous information. It effectively uses the source\n",
            "text as evidence and is properly contextualized, offering a clear and correct\n",
            "answer to the question.\n",
            "\n",
            "================================================================================\n",
            "OVERALL ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Performance Summary:\n",
            "--------------------------------------------------------------------------------\n",
            "Average composite score across all evaluations: 73.82/100\n",
            "\n",
            "Optimal Configuration:\n",
            "--------------------------------------------------------------------------------\n",
            "Best performance: open-mistral-nemo with threshold 95 (score: 88.75/100)\n",
            "\n",
            "Performance Analysis:\n",
            "--------------------------------------------------------------------------------\n",
            "Evaluated 30 responses across 6 model/threshold combinations.\n",
            "\n",
            "================================================================================\n",
            "METADATA\n",
            "================================================================================\n",
            "Timestamp:           2024-11-13T16:36:49.785876\n",
            "Model Used:          gpt-4o\n",
            "Permutations:        30\n",
            "Questions Evaluated: 5\n",
            "Evaluation Status:   success\n",
            "\n",
            "Step 3: Returning evaluation\n",
            "\n",
            "=== Starting Results Formatting ===\n",
            "Input evaluation_results keys: ['metadata', 'evaluations', 'summary']\n",
            "\n",
            "=== Results Formatting Complete ===\n",
            "\n",
            "Experiment and evaluation completed successfully\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    global _GLOBAL_RAG_PIPELINE\n",
        "    if _GLOBAL_RAG_PIPELINE is not None:\n",
        "        print(\"Existing RAG piple and associated document chunks found. Preserving cached chunks...\")\n",
        "\n",
        "    # Single temperature setting for all models\n",
        "    GLOBAL_TEMPERATURE = 0.3\n",
        "\n",
        "    config = MemoryOptimizedExperimentConfig(\n",
        "        models=MODEL_CONFIGS[\"models\"],\n",
        "        thresholds=MODEL_CONFIGS[\"thresholds\"],\n",
        "        questions=QUESTION_CONFIGS[\"questions\"],\n",
        "        temperature=GLOBAL_TEMPERATURE\n",
        "    )\n",
        "\n",
        "    print(\"Starting experiment with configurations:\")\n",
        "    print(f\"Global temperature: {GLOBAL_TEMPERATURE}\")\n",
        "    print(f\"Models: {[model['name'] for model in config.models]}\")\n",
        "    print(f\"Thresholds: {config.thresholds}\")\n",
        "    print(f\"Number of questions: {len(config.questions)}\")\n",
        "\n",
        "    # Run the experiment\n",
        "    results = config.run_experiment()\n",
        "\n",
        "    # Get source document text from the global documents variable\n",
        "    source_doc = documents[0].text  # documents is loaded at the start of this script\n",
        "\n",
        "    # Initialize the evaluator\n",
        "    print(\"\\nInitializing GPT-4 evaluation...\")\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "    evaluator = ExperimentEvaluator(openai_api_key)\n",
        "\n",
        "    # Run evaluation and get intermediate formatted results\n",
        "    evaluation = evaluator.evaluate_and_format(results, source_doc)\n",
        "\n",
        "    # Format and save final results\n",
        "    formatted_results, formatted_evaluation = evaluator.format_and_save_results(\n",
        "        results,\n",
        "        evaluation,\n",
        "        FILE_CONFIGS['save_directory']\n",
        "    )\n",
        "\n",
        "    print(\"\\nExperiment and evaluation completed successfully\")\n",
        "    return formatted_results, formatted_evaluation\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results, evaluation = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vClfo1_AR5rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yxCYWFPZs--Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}